#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç ”ç©¶è®¾è®¡æŠ€èƒ½ - æ–‡çŒ®åˆ†ææ¨¡å—
æä¾›æ–‡çŒ®æ”¶é›†ã€æ•´ç†ã€åˆ†æå’ŒçŸ¥è¯†ç¼ºå£è¯†åˆ«åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import warnings
import re
from datetime import datetime


class LiteratureAnalyzer:
    """æ–‡çŒ®åˆ†æå™¨ - åˆ†æç ”ç©¶é¢†åŸŸçš„æ–‡çŒ®çŠ¶å†µ"""
    
    def __init__(self):
        self.literature_data = None
        self.analysis_results = {}
        
    def load_literature_data(self, data: Union[str, pd.DataFrame]) -> pd.DataFrame:
        """
        åŠ è½½æ–‡çŒ®æ•°æ®
        
        Args:
            data: CSVæ–‡ä»¶è·¯å¾„æˆ–DataFrame
            
        Returns:
            DataFrame: æ–‡çŒ®æ•°æ®
        """
        if isinstance(data, str):
            self.literature_data = pd.read_csv(data)
        else:
            self.literature_data = data.copy()
            
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_columns = ['title', 'author', 'year', 'journal', 'abstract']
        for col in required_columns:
            if col not in self.literature_data.columns:
                # åˆ›å»ºè™šæ‹Ÿåˆ—
                self.literature_data[col] = ""
                
        return self.literature_data
    
    def analyze_publication_trends(self) -> Dict[str, Any]:
        """
        åˆ†æå‡ºç‰ˆè¶‹åŠ¿
        
        Returns:
            Dict: å‡ºç‰ˆè¶‹åŠ¿åˆ†æç»“æœ
        """
        if self.literature_data is None:
            return {}
            
        # ç¡®ä¿yearåˆ—å­˜åœ¨ä¸”ä¸ºæ•°å€¼
        if 'year' in self.literature_data.columns:
            year_data = pd.to_numeric(self.literature_data['year'], errors='coerce')
            year_counts = year_data.value_counts().sort_index()
            
            trend_analysis = {
                'yearly_publications': year_counts.to_dict(),
                'total_publications': len(self.literature_data),
                'publication_period': {
                    'start_year': int(year_counts.index.min()) if not year_counts.empty else 0,
                    'end_year': int(year_counts.index.max()) if not year_counts.empty else 0,
                    'span_years': int(year_counts.index.max() - year_counts.index.min() + 1) if not year_counts.empty else 0
                },
                'average_annual_output': float(year_counts.mean()) if not year_counts.empty else 0.0
            }
        else:
            trend_analysis = {
                'yearly_publications': {},
                'total_publications': len(self.literature_data),
                'publication_period': {
                    'start_year': 0,
                    'end_year': 0,
                    'span_years': 0
                },
                'average_annual_output': 0.0
            }
            
        self.analysis_results['trend_analysis'] = trend_analysis
        return trend_analysis
    
    def analyze_research_themes(self, top_n: int = 10) -> Dict[str, Any]:
        """
        åˆ†æç ”ç©¶ä¸»é¢˜
        
        Args:
            top_n: è¿”å›å‰Nä¸ªä¸»é¢˜
            
        Returns:
            Dict: ç ”ç©¶ä¸»é¢˜åˆ†æç»“æœ
        """
        if self.literature_data is None:
            return {}
            
        # ä»æ ‡é¢˜å’Œæ‘˜è¦ä¸­æå–å…³é”®è¯
        all_texts = []
        if 'title' in self.literature_data.columns:
            all_texts.extend(self.literature_data['title'].fillna('').astype(str).tolist())
        if 'abstract' in self.literature_data.columns:
            all_texts.extend(self.literature_data['abstract'].fillna('').astype(str).tolist())
        
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„NLPæŠ€æœ¯ï¼‰
        all_text = ' '.join(all_texts).lower()
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œæå–å•è¯
        words = re.findall(r'\b[a-zA-Z]{4,}\b', all_text)  # åªæå–4ä¸ªå­—æ¯ä»¥ä¸Šçš„å•è¯
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # æ’åºå¹¶è¿”å›top_n
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:top_n]
        
        theme_analysis = {
            'top_keywords': dict(sorted_words),
            'total_unique_terms': len(word_freq),
            'dominant_themes': [word for word, count in sorted_words]
        }
        
        self.analysis_results['theme_analysis'] = theme_analysis
        return theme_analysis
    
    def identify_knowledge_gaps(self) -> List[Dict[str, Any]]:
        """
        è¯†åˆ«çŸ¥è¯†ç¼ºå£
        
        Returns:
            List: çŸ¥è¯†ç¼ºå£åˆ—è¡¨
        """
        if self.literature_data is None:
            return []
            
        gaps = []
        
        # åŸºäºå‡ºç‰ˆè¶‹åŠ¿è¯†åˆ«å¯èƒ½çš„çŸ¥è¯†ç¼ºå£
        trend_analysis = self.analysis_results.get('trend_analysis', {})
        if trend_analysis:
            yearly_pub = trend_analysis.get('yearly_publications', {})
            if yearly_pub:
                years = list(yearly_pub.keys())
                if len(years) > 1:
                    # æŸ¥æ‰¾å‡ºç‰ˆé‡æ˜¾è‘—ä¸‹é™çš„å¹´ä»½
                    avg_pub = np.mean(list(yearly_pub.values()))
                    low_pub_years = [year for year, count in yearly_pub.items() 
                                   if count < avg_pub * 0.5 and count > 0]
                    
                    if low_pub_years:
                        gaps.append({
                            'gap_type': 'temporal',
                            'description': f'å‡ºç‰ˆé‡è¾ƒä½çš„å¹´ä»½: {low_pub_years}',
                            'significance': 'å¯èƒ½åæ˜ ç ”ç©¶å…´è¶£æˆ–èµ„æºæŠ•å…¥çš„å˜åŒ–'
                        })
        
        # åŸºäºä¸»é¢˜åˆ†æè¯†åˆ«çŸ¥è¯†ç¼ºå£
        theme_analysis = self.analysis_results.get('theme_analysis', {})
        if theme_analysis:
            top_keywords = theme_analysis.get('top_keywords', {})
            if len(top_keywords) < 10:  # å¦‚æœé«˜é¢‘è¯æ±‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨ç ”ç©¶ç©ºç™½
                gaps.append({
                    'gap_type': 'thematic',
                    'description': f'é«˜é¢‘ç ”ç©¶ä¸»é¢˜è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨ç ”ç©¶ç©ºç™½',
                    'significance': 'ç ”ç©¶é¢†åŸŸå¯èƒ½è¾ƒä¸ºæ–°é¢–æˆ–åˆ†æ•£'
                })
        
        # åŸºäºæ–‡çŒ®æ•°é‡è¯†åˆ«çŸ¥è¯†ç¼ºå£
        if len(self.literature_data) < 50:  # åªè®¾å°‘äº50ç¯‡ä¸ºç ”ç©¶ä¸è¶³
            gaps.append({
                'gap_type': 'volume',
                'description': f'æ–‡çŒ®æ€»æ•°è¾ƒå°‘ ({len(self.literature_data)} ç¯‡)',
                'significance': 'ç ”ç©¶é¢†åŸŸå¯èƒ½è¾ƒæ–°æˆ–å…³æ³¨åº¦ä¸è¶³'
            })
        
        self.analysis_results['knowledge_gaps'] = gaps
        return gaps
    
    def generate_literature_report(self) -> str:
        """
        ç”Ÿæˆæ–‡çŒ®åˆ†ææŠ¥å‘Š
        
        Returns:
            str: åˆ†ææŠ¥å‘Š
        """
        if self.literature_data is None:
            return "æœªåŠ è½½æ–‡çŒ®æ•°æ®"
            
        report = []
        report.append("# æ–‡çŒ®åˆ†ææŠ¥å‘Š\n")
        report.append(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # åŸºæœ¬ç»Ÿè®¡
        report.append("## åŸºæœ¬ç»Ÿè®¡\n")
        report.append(f"- æ–‡çŒ®æ€»æ•°: {len(self.literature_data)} ç¯‡\n")
        report.append(f"- æ•°æ®æ—¶é—´èŒƒå›´: {self.literature_data.get('year', pd.Series()).min()} - {self.literature_data.get('year', pd.Series()).max()}\n\n")
        
        # å‡ºç‰ˆè¶‹åŠ¿
        trend_analysis = self.analysis_results.get('trend_analysis', {})
        if trend_analysis:
            report.append("## å‡ºç‰ˆè¶‹åŠ¿\n")
            period = trend_analysis.get('publication_period', {})
            report.append(f"- å‡ºç‰ˆæ—¶é—´è·¨åº¦: {period.get('start_year', 'N/A')} - {period.get('end_year', 'N/A')} ({period.get('span_years', 'N/A')} å¹´)\n")
            report.append(f"- å¹´å‡å‡ºç‰ˆé‡: {trend_analysis.get('average_annual_output', 0):.2f} ç¯‡\n\n")
        
        # ç ”ç©¶ä¸»é¢˜
        theme_analysis = self.analysis_results.get('theme_analysis', {})
        if theme_analysis:
            report.append("## ä¸»è¦ç ”ç©¶ä¸»é¢˜\n")
            top_keywords = list(theme_analysis.get('top_keywords', {}).keys())[:5]
            report.append("- " + ", ".join(top_keywords) + "\n\n")
        
        # çŸ¥è¯†ç¼ºå£
        knowledge_gaps = self.analysis_results.get('knowledge_gaps', [])
        if knowledge_gaps:
            report.append("## è¯†åˆ«çš„çŸ¥è¯†ç¼ºå£\n")
            for gap in knowledge_gaps:
                report.append(f"- **{gap['gap_type']}**: {gap['description']}\n")
                report.append(f"  - æ„ä¹‰: {gap['significance']}\n\n")
        else:
            report.append("## çŸ¥è¯†ç¼ºå£\n")
            report.append("æœªè¯†åˆ«åˆ°æ˜æ˜¾çš„çŸ¥è¯†ç¼ºå£\n\n")
        
        # å»ºè®®
        report.append("## ç ”ç©¶å»ºè®®\n")
        if knowledge_gaps:
            report.append("åŸºäºè¯†åˆ«çš„çŸ¥è¯†ç¼ºå£ï¼Œå»ºè®®åœ¨ä»¥ä¸‹æ–¹é¢åŠ å¼ºç ”ç©¶ï¼š\n")
            for gap in knowledge_gaps:
                report.append(f"- {gap['description']}\n")
        else:
            report.append("å½“å‰ç ”ç©¶é¢†åŸŸæ–‡çŒ®è¾ƒä¸ºä¸°å¯Œï¼Œå»ºè®®æ·±åŒ–ç°æœ‰ç ”ç©¶æ–¹å‘æˆ–æ¢ç´¢è·¨é¢†åŸŸæ•´åˆã€‚\n")
        
        return "".join(report)


def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    print("ğŸ“š ç ”ç©¶è®¾è®¡ - æ–‡çŒ®åˆ†ææ¨¡å—æ¼”ç¤º")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    sample_data = pd.DataFrame({
        'title': [
            'The Impact of Social Media on Mental Health',
            'Digital Technology and Psychological Well-being',
            'Social Networks Effects on Individual Behavior',
            'Technology Adoption in Modern Society',
            'Psychological Factors in Digital Engagement',
            'Social Media Usage Patterns Among Youth',
            'Digital Divide and Access to Technology',
            'Online Communities and Social Support',
            'Cyberbullying and Mental Health Outcomes',
            'Privacy Concerns in Digital Age'
        ],
        'author': [
            'Smith, J.', 'Johnson, A.', 'Williams, R.',
            'Brown, S.', 'Davis, M.', 'Miller, T.',
            'Wilson, K.', 'Moore, L.', 'Taylor, P.', 'Anderson, H.'
        ],
        'year': np.random.choice(range(2018, 2024), 10),
        'journal': [
            'Journal of Psychology', 'Digital Society Review', 'Tech & Behavior',
            'Modern Psychology', 'Cyberpsychology', 'Social Science Today',
            'Technology Quarterly', 'Digital Research', 'Psychological Science',
            'Online Behavior Studies'
        ],
        'abstract': [
            'This study examines the relationship between social media usage and mental health outcomes...',
            'Research on how digital technology affects psychological well-being...',
            'Analysis of how social networks influence individual behavioral patterns...',
            'Investigation of technology adoption trends in contemporary society...',
            'Study of psychological factors affecting digital engagement...',
            'Patterns of social media usage among young people...',
            'Examining the digital divide and technology access issues...',
            'Role of online communities in providing social support...',
            'Impact of cyberbullying on mental health outcomes...',
            'Privacy concerns in the age of digital technology...'
        ]
    })
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = LiteratureAnalyzer()
    
    # åŠ è½½æ•°æ®
    analyzer.load_literature_data(sample_data)
    
    # æ‰§è¡Œåˆ†æ
    trend_analysis = analyzer.analyze_publication_trends()
    theme_analysis = analyzer.analyze_research_themes(top_n=5)
    knowledge_gaps = analyzer.identify_knowledge_gaps()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_literature_report()
    print(report)
    
    print("âœ… æ–‡çŒ®åˆ†æå®Œæˆï¼")


if __name__ == "__main__":
    main()