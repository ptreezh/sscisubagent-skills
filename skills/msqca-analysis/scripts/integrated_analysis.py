#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
msQCAé›†æˆåˆ†æè„šæœ¬ - å®šæ€§ä¸å®šé‡å®Œç¾ç»“åˆçš„æ ¸å¿ƒå¼•æ“
æ ¹æ®AIåˆ†æå†³ç­–ï¼Œè°ƒç”¨ç›¸åº”çš„å®šæ€§æç¤ºè¯å’Œå®šé‡ç®—æ³•
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import json
import os
from pathlib import Path
import warnings

# å¯¼å…¥å®šé‡åˆ†ææ¨¡å—
from calibration import QCACalibration
from truth_table import TruthTableBuilder
from minimization import BooleanMinimizer


class IntegratedQCAAnalyzer:
    """é›†æˆQCAåˆ†æå™¨ - å®šæ€§ä¸å®šé‡å®Œç¾ç»“åˆ"""
    
    def __init__(self, skill_root: str):
        self.skill_root = Path(skill_root)
        self.prompts_dir = self.skill_root / "prompts"
        self.scripts_dir = self.skill_root / "scripts"
        self.references_dir = self.skill_root / "references"
        
        # åˆå§‹åŒ–å®šé‡åˆ†æç»„ä»¶
        self.calibrator = QCACalibration()
        self.truth_table_builder = TruthTableBuilder()
        self.minimizer = BooleanMinimizer()
        
        # åˆ†æçŠ¶æ€è·Ÿè¸ª
        self.analysis_state = {
            'phase': 'initiated',
            'theoretical_analysis': None,
            'calibration_plan': None,
            'quantitative_results': None,
            'interpretation': None
        }
    
    def load_prompt_content(self, prompt_name: str) -> str:
        """åŠ è½½æç¤ºè¯å†…å®¹"""
        prompt_file = self.prompts_dir / f"{prompt_name}.md"
        if not prompt_file.exists():
            raise FileNotFoundError(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    
    def execute_theoretical_analysis(self, 
                                   research_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç†è®ºåˆ†æé˜¶æ®µ
        
        è¿™ä¸ªæ–¹æ³•ä¼šåŠ è½½ç†è®ºåˆ†ææç¤ºè¯ï¼ŒæŒ‡å¯¼AIè¿›è¡Œæ·±åº¦ç†è®ºåˆ†æ
        """
        print("ğŸ¯ å¼€å§‹ç†è®ºåˆ†æé˜¶æ®µ...")
        
        # åŠ è½½ç†è®ºåˆ†ææç¤ºè¯
        theoretical_prompt = self.load_prompt_content("theoretical-analysis")
        
        # æ„å»ºç†è®ºåˆ†ææŒ‡å¯¼
        analysis_guidance = {
            'prompt_content': theoretical_prompt,
            'research_context': research_context,
            'analysis_focus': [
                'theoretical_framework',
                'condition_selection', 
                'causal_mechanisms',
                'calibration_theory'
            ],
            'output_requirements': {
                'theoretical_framework': 'æ ¸å¿ƒæ¦‚å¿µå’Œå‡è®¾',
                'selected_conditions': 'æ¡ä»¶å˜é‡é€‰æ‹©ç†ç”±',
                'causal_paths': 'é¢„æœŸå› æœè·¯å¾„',
                'calibration_guidance': 'æ ¡å‡†ç†è®ºä¾æ®'
            }
        }
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'theoretical_analysis'
        self.analysis_state['theoretical_analysis'] = analysis_guidance
        
        return analysis_guidance
    
    def execute_calibration_guidance(self,
                                   data: pd.DataFrame,
                                   theoretical_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ ¡å‡†æŒ‡å¯¼é˜¶æ®µ
        
        ç»“åˆç†è®ºåˆ†æå’Œæ•°æ®ç‰¹å¾ï¼Œåˆ¶å®šæ ¡å‡†æ–¹æ¡ˆ
        """
        print("ğŸ“Š åˆ¶å®šæ ¡å‡†æ–¹æ¡ˆ...")
        
        # åŠ è½½æ ¡å‡†æŒ‡å¯¼æç¤ºè¯
        calibration_prompt = self.load_prompt_content("calibration-guidance")
        
        # æ•°æ®ç‰¹å¾åˆ†æ
        data_characteristics = self._analyze_data_characteristics(data)
        
        # æ„å»ºæ ¡å‡†æŒ‡å¯¼
        calibration_guidance = {
            'prompt_content': calibration_prompt,
            'data_characteristics': data_characteristics,
            'theoretical_analysis': theoretical_analysis,
            'calibration_decisions': {},
            'quality_checks': []
        }
        
        # ä¸ºæ¯ä¸ªå˜é‡åˆ¶å®šæ ¡å‡†æ–¹æ¡ˆ
        for column in data.columns:
            if column != 'case_id' and column != 'case_description':
                var_info = data_characteristics[column]
                calibration_plan = self._create_variable_calibration_plan(
                    column, var_info, theoretical_analysis
                )
                calibration_guidance['calibration_decisions'][column] = calibration_plan
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'calibration_guidance'
        self.analysis_state['calibration_plan'] = calibration_guidance
        
        return calibration_guidance
    
    def execute_quantitative_analysis(self,
                                    data: pd.DataFrame,
                                    conditions: List[str],
                                    outcome: str,
                                    calibration_plan: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®šé‡åˆ†æé˜¶æ®µ
        
        æ ¹æ®æ ¡å‡†è®¡åˆ’æ‰§è¡Œå…·ä½“çš„å®šé‡è®¡ç®—
        """
        print("ğŸ”¬ æ‰§è¡Œå®šé‡åˆ†æ...")
        
        # ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œæ ¡å‡†
        print("  - æ‰§è¡Œæ•°æ®æ ¡å‡†...")
        calibrated_data = self._perform_calibration(data, calibration_plan)
        
        # ç¬¬äºŒæ­¥ï¼šæ„å»ºçœŸå€¼è¡¨
        print("  - æ„å»ºçœŸå€¼è¡¨...")
        truth_table = self.truth_table_builder.build_truth_table(
            calibrated_data, conditions, outcome
        )
        
        # å¤„ç†çŸ›ç›¾ç»„åˆ
        if len(self.truth_table_builder.contradictory_cases) > 0:
            print("  - å¤„ç†çŸ›ç›¾ç»„åˆ...")
            truth_table = self.truth_table_builder.handle_contradictions(method='remove')
        
        # ç¬¬ä¸‰æ­¥ï¼šé€»è¾‘æœ€å°åŒ–
        print("  - æ‰§è¡Œé€»è¾‘æœ€å°åŒ–...")
        solutions = self.minimizer.minimize(truth_table, conditions)
        
        # ç¬¬å››æ­¥ï¼šè´¨é‡è¯„ä¼°
        print("  - è¯„ä¼°åˆ†æè´¨é‡...")
        quality_metrics = self._calculate_analysis_quality(
            calibrated_data, truth_table, solutions
        )
        
        # æ•´åˆå®šé‡ç»“æœ
        quantitative_results = {
            'calibrated_data': calibrated_data,
            'truth_table': truth_table,
            'solutions': solutions,
            'quality_metrics': quality_metrics,
            'technical_details': {
                'n_cases': len(calibrated_data),
                'n_conditions': len(conditions),
                'n_positive_cases': len(truth_table[truth_table['result_type'] == 1]),
                'n_contradictions': len(self.truth_table_builder.contradictory_cases),
                'n_logical_remainders': len(self.truth_table_builder.logical_remainders)
            }
        }
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'quantitative_analysis'
        self.analysis_state['quantitative_results'] = quantitative_results
        
        return quantitative_results
    
    def execute_result_interpretation(self,
                                    quantitative_results: Dict[str, Any],
                                    theoretical_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç»“æœè§£é‡Šé˜¶æ®µ
        
        åŠ è½½ç»“æœè§£é‡Šæç¤ºè¯ï¼ŒæŒ‡å¯¼AIè¿›è¡Œæ·±åº¦ç»“æœè§£é‡Š
        """
        print("ğŸ“ æ·±åº¦è§£é‡Šåˆ†æç»“æœ...")
        
        # åŠ è½½ç»“æœè§£é‡Šæç¤ºè¯
        interpretation_prompt = self.load_prompt_content("result-interpretation")
        
        # å‡†å¤‡è§£é‡Šæ‰€éœ€çš„ä¿¡æ¯
        interpretation_context = {
            'prompt_content': interpretation_prompt,
            'quantitative_results': quantitative_results,
            'theoretical_analysis': theoretical_analysis,
            'interpretation_focus': [
                'solution_analysis',
                'causal_mechanisms',
                'theoretical_contributions',
                'practical_implications'
            ]
        }
        
        # ç”Ÿæˆè§£é‡ŠæŒ‡å¯¼
        interpretation_guidance = self._create_interpretation_guidance(
            quantitative_results, theoretical_analysis
        )
        
        interpretation_context['interpretation_guidance'] = interpretation_guidance
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'result_interpretation'
        self.analysis_state['interpretation'] = interpretation_context
        
        return interpretation_context
    
    def _analyze_data_characteristics(self, data: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ•°æ®ç‰¹å¾"""
        characteristics = {}
        
        for column in data.columns:
            if column not in ['case_id', 'case_description']:
                col_data = data[column].dropna()
                
                characteristics[column] = {
                    'type': self._determine_variable_type(col_data),
                    'n_missing': data[column].isna().sum(),
                    'missing_rate': data[column].isna().sum() / len(data),
                    'unique_values': col_data.nunique(),
                    'value_range': [col_data.min(), col_data.max()] if col_data.dtype in ['int64', 'float64'] else list(col_data.unique()),
                    'distribution': self._describe_distribution(col_data)
                }
        
        return characteristics
    
    def _determine_variable_type(self, series: pd.Series) -> str:
        """ç¡®å®šå˜é‡ç±»å‹"""
        if series.dtype in ['int64', 'float64']:
            if series.nunique() <= 10:
                return 'discrete_numeric'
            else:
                return 'continuous'
        else:
            if series.nunique() <= 10:
                return 'categorical'
            else:
                return 'text'
    
    def _describe_distribution(self, series: pd.Series) -> Dict[str, Any]:
        """æè¿°æ•°æ®åˆ†å¸ƒ"""
        if series.dtype in ['int64', 'float64']:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©ºæˆ–å…¨éƒ¨ä¸ºNaN
            if len(series) == 0 or series.isna().all():
                return {
                    'mean': np.nan,
                    'std': np.nan,
                    'skewness': np.nan,
                    'kurtosis': np.nan,
                    'distribution_shape': 'undefined'
                }

            # ä½¿ç”¨å®‰å…¨çš„ç»Ÿè®¡è®¡ç®—
            return {
                'mean': series.mean() if not np.isnan(series.mean()) else np.nan,
                'std': series.std() if not np.isnan(series.std()) else np.nan,
                'skewness': series.skew() if not np.isnan(series.skew()) else np.nan,
                'kurtosis': series.kurtosis() if not np.isnan(series.kurtosis()) else np.nan,
                'distribution_shape': self._identify_distribution_shape(series.dropna())
            }
        else:
            value_counts = series.value_counts()
            return {
                'value_counts': value_counts.to_dict(),
                'most_common': value_counts.index[0] if len(value_counts) > 0 else None
            }
    
    def _identify_distribution_shape(self, series: pd.Series) -> str:
        """è¯†åˆ«åˆ†å¸ƒå½¢çŠ¶"""
        skewness = series.skew()
        kurtosis = series.kurtosis()
        
        if abs(skewness) < 0.5 and abs(kurtosis) < 0.5:
            return 'normal'
        elif skewness > 1:
            return 'right_skewed'
        elif skewness < -1:
            return 'left_skewed'
        elif kurtosis > 1:
            return 'heavy_tailed'
        else:
            return 'irregular'
    
    def _create_variable_calibration_plan(self,
                                        variable: str,
                                        var_info: Dict[str, Any],
                                        theoretical_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸ºå˜é‡åˆ›å»ºæ ¡å‡†è®¡åˆ’"""
        plan = {
            'variable': variable,
            'variable_type': var_info['type'],
            'data_quality': {
                'missing_rate': var_info['missing_rate'],
                'unique_values': var_info['unique_values']
            }
        }
        
        # æ ¹æ®å˜é‡ç±»å‹æ¨èæ ¡å‡†æ–¹æ³•
        if var_info['type'] == 'continuous':
            if var_info['unique_values'] > 20:
                plan['recommended_method'] = 'direct'
                plan['reason'] = 'è¿ç»­å˜é‡ï¼Œå–å€¼ä¸°å¯Œï¼Œé€‚åˆç›´æ¥æ ¡å‡†'
            else:
                plan['recommended_method'] = 'indirect'
                plan['reason'] = 'è¿ç»­å˜é‡ä½†å–å€¼æœ‰é™ï¼Œé€‚åˆé—´æ¥æ ¡å‡†'
        elif var_info['type'] == 'discrete_numeric':
            plan['recommended_method'] = 'multi_value'
            plan['reason'] = 'ç¦»æ•£æ•°å€¼å˜é‡ï¼Œé€‚åˆå¤šå€¼æ ¡å‡†'
        else:
            plan['recommended_method'] = 'multi_value'
            plan['reason'] = 'åˆ†ç±»å˜é‡ï¼Œé€‚åˆå¤šå€¼æ ¡å‡†'
        
        # å¦‚æœæœ‰ç†è®ºåˆ†æï¼Œæ•´åˆç†è®ºæŒ‡å¯¼
        if theoretical_analysis and 'calibration_guidance' in theoretical_analysis:
            plan['theoretical_guidance'] = theoretical_analysis['calibration_guidance']
        
        return plan
    
    def _perform_calibration(self,
                           data: pd.DataFrame,
                           calibration_plan: Dict[str, Any]) -> pd.DataFrame:
        """æ‰§è¡Œæ•°æ®æ ¡å‡†"""
        calibrated_data = data.copy()
        
        for variable, plan in calibration_plan['calibration_decisions'].items():
            if variable in data.columns:
                method = plan['recommended_method']
                
                # æ ¹æ®è®¡åˆ’æ‰§è¡Œæ ¡å‡†
                if method == 'auto':
                    calibrated_series = self.calibrator.calibrate_variable(
                        data[variable], method='auto'
                    )
                elif method == 'direct':
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„é˜ˆå€¼è®¾å®š
                    calibrated_series = self.calibrator.calibrate_variable(
                        data[variable], method='direct'
                    )
                elif method == 'indirect':
                    calibrated_series = self.calibrator.calibrate_variable(
                        data[variable], method='indirect'
                    )
                elif method == 'multi_value':
                    calibrated_series = self.calibrator.calibrate_variable(
                        data[variable], method='multi_value'
                    )
                else:
                    calibrated_series = data[variable]  # ä¿æŒåŸå€¼
                
                calibrated_data[variable] = calibrated_series
        
        return calibrated_data
    
    def _calculate_analysis_quality(self,
                                  calibrated_data: pd.DataFrame,
                                  truth_table: pd.DataFrame,
                                  solutions: List) -> Dict[str, Any]:
        """è®¡ç®—åˆ†æè´¨é‡æŒ‡æ ‡"""
        quality_metrics = {}

        # æ•°æ®è´¨é‡æŒ‡æ ‡
        if calibrated_data.size > 0:
            completeness = 1.0 - calibrated_data.isna().sum().sum() / calibrated_data.size
            calibration_coverage = len(calibrated_data.dropna()) / len(calibrated_data) if len(calibrated_data) > 0 else 0
            quality_metrics['data_quality'] = {
                'completeness': completeness if not np.isnan(completeness) else 0.0,
                'calibration_coverage': calibration_coverage
            }
        else:
            quality_metrics['data_quality'] = {
                'completeness': 0.0,
                'calibration_coverage': 0.0
            }

        # çœŸå€¼è¡¨è´¨é‡æŒ‡æ ‡
        truth_table_quality = self.truth_table_builder.calculate_quality_metrics()
        quality_metrics['truth_table_quality'] = truth_table_quality

        # è§£è´¨é‡æŒ‡æ ‡
        if solutions:
            # è¿‡æ»¤æ‰æ— æ•ˆè§£ï¼ˆcoverageæˆ–consistencyä¸ºNaNçš„è§£ï¼‰
            valid_solutions = [sol for sol in solutions if not (np.isnan(sol.coverage) or np.isnan(sol.consistency))]
            if valid_solutions:
                best_solution = max(valid_solutions, key=lambda x: x.coverage * x.consistency)
                quality_metrics['solution_quality'] = {
                    'best_coverage': best_solution.coverage,
                    'best_consistency': best_solution.consistency,
                    'solution_complexity': best_solution.complexity,
                    'n_solutions': len(solutions)
                }

        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_metrics['overall_quality'] = self._calculate_overall_quality(quality_metrics)

        return quality_metrics
    
    def _calculate_overall_quality(self, quality_metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°"""
        # ä»è´¨é‡æŒ‡æ ‡ä¸­è·å–æ•°æ®è´¨é‡åˆ†æ•°
        data_quality = quality_metrics.get('data_quality', {})
        data_score = data_quality.get('completeness', 0.0)

        # å¤„ç†NaNå€¼
        if np.isnan(data_score):
            data_score = 0.0

        # è·å–çœŸå€¼è¡¨è´¨é‡åˆ†æ•°
        if 'truth_table_quality' in quality_metrics:
            contradiction_rate = quality_metrics['truth_table_quality'].get('contradiction_rate', 0.0)
            if np.isnan(contradiction_rate):
                contradiction_rate = 0.0
            table_score = min(1.0, 1.0 - contradiction_rate)
        else:
            table_score = 0.5

        # è·å–è§£è´¨é‡åˆ†æ•°
        if 'solution_quality' in quality_metrics:
            best_coverage = quality_metrics['solution_quality'].get('best_coverage', 0.0)
            best_consistency = quality_metrics['solution_quality'].get('best_consistency', 0.0)

            # å¤„ç†NaNå€¼
            if np.isnan(best_coverage):
                best_coverage = 0.0
            if np.isnan(best_consistency):
                best_consistency = 0.0

            solution_score = (best_coverage + best_consistency) / 2
        else:
            solution_score = 0.5

        # å¤„ç†å¯èƒ½çš„NaNå€¼
        if np.isnan(data_score):
            data_score = 0.0
        if np.isnan(table_score):
            table_score = 0.0
        if np.isnan(solution_score):
            solution_score = 0.0

        # åŠ æƒå¹³å‡
        overall_score = (data_score * 0.3 + table_score * 0.4 + solution_score * 0.3)

        # ç¡®ä¿ç»“æœæ˜¯æœ‰æ•ˆæ•°å€¼
        if np.isnan(overall_score) or np.isinf(overall_score):
            overall_score = 0.0

        return overall_score
    
    def _create_interpretation_guidance(self,
                                      quantitative_results: Dict[str, Any],
                                      theoretical_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºç»“æœè§£é‡ŠæŒ‡å¯¼"""
        guidance = {
            'solutions_summary': [],
            'key_findings': [],
            'interpretation_questions': []
        }
        
        # æ€»ç»“è§£æ–¹æ¡ˆ
        for i, solution in enumerate(quantitative_results['solutions']):
            solution_summary = {
                'solution_id': i + 1,
                'type': solution.solution_type.value,
                'expression': solution.expression,
                'coverage': solution.coverage,
                'consistency': solution.consistency,
                'complexity': solution.complexity
            }
            guidance['solutions_summary'].append(solution_summary)
        
        # è¯†åˆ«å…³é”®å‘ç°
        best_solution = max(quantitative_results['solutions'], 
                          key=lambda x: x.coverage * x.consistency)
        
        guidance['key_findings'] = [
            f"æœ€ä¼˜è§£è¦†ç›–åº¦: {best_solution.coverage:.3f}",
            f"æœ€ä¼˜è§£ä¸€è‡´æ€§: {best_solution.consistency:.3f}",
            f"è´¨è•´å«é¡¹æ•°é‡: {len(best_solution.prime_implicants)}",
            f"æ¡ˆä¾‹æ€»æ•°: {quantitative_results['technical_details']['n_cases']}",
            f"æ­£é¢æ¡ˆä¾‹æ•°: {quantitative_results['technical_details']['n_positive_cases']}"
        ]
        
        # ç”Ÿæˆè§£é‡Šé—®é¢˜
        guidance['interpretation_questions'] = [
            "è¿™äº›å› æœè·¯å¾„èƒŒåçš„ç†è®ºæœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ä¸åŒè·¯å¾„é€‚ç”¨äºä»€ä¹ˆæ ·çš„æƒ…å¢ƒæ¡ä»¶ï¼Ÿ",
            "ç ”ç©¶å‘ç°å¯¹ç°æœ‰ç†è®ºæœ‰ä»€ä¹ˆè´¡çŒ®ï¼Ÿ",
            "å¦‚ä½•å°†è¿™äº›å‘ç°è½¬åŒ–ä¸ºå®è·µå»ºè®®ï¼Ÿ",
            "ç ”ç©¶çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Œæœªæ¥ç ”ç©¶æ–¹å‘å¦‚ä½•ï¼Ÿ"
        ]
        
        return guidance
    
    def generate_analysis_report(self, output_file: str = None) -> str:
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
        report_sections = []
        
        # æŠ¥å‘Šæ ‡é¢˜
        report_sections.append("# msQCAé›†æˆåˆ†ææŠ¥å‘Š\n")
        
        # ç†è®ºåˆ†æéƒ¨åˆ†
        if self.analysis_state['theoretical_analysis']:
            report_sections.append("## ğŸ¯ ç†è®ºåˆ†æ\n")
            report_sections.append("ç†è®ºåˆ†æå·²å®Œæˆï¼Œè¯¦è§åˆ†ææŒ‡å¯¼æ–‡æ¡£ã€‚\n")
        
        # æ ¡å‡†æ–¹æ¡ˆéƒ¨åˆ†
        if self.analysis_state['calibration_plan']:
            report_sections.append("## ğŸ“Š æ ¡å‡†æ–¹æ¡ˆ\n")
            calibration_plan = self.analysis_state['calibration_plan']
            for var, plan in calibration_plan['calibration_decisions'].items():
                report_sections.append(f"**{var}**: {plan['recommended_method']} - {plan['reason']}\n")
        
        # å®šé‡ç»“æœéƒ¨åˆ†
        if self.analysis_state['quantitative_results']:
            report_sections.append("## ğŸ”¬ å®šé‡åˆ†æç»“æœ\n")
            results = self.analysis_state['quantitative_results']
            
            report_sections.append("### è´¨é‡æŒ‡æ ‡\n")
            quality = results['quality_metrics']
            report_sections.append(f"- æ•°æ®å®Œæ•´æ€§: {quality['data_quality']['completeness']:.3f}\n")
            report_sections.append(f"- ç»¼åˆè´¨é‡: {quality['overall_quality']:.3f}\n")
            
            report_sections.append("### æœ€ä¼˜è§£\n")
            best_solution = max(results['solutions'], key=lambda x: x.coverage * x.consistency)
            report_sections.append(f"- è¡¨è¾¾å¼: {best_solution.expression}\n")
            report_sections.append(f"- è¦†ç›–åº¦: {best_solution.coverage:.3f}\n")
            report_sections.append(f"- ä¸€è‡´æ€§: {best_solution.consistency:.3f}\n")
        
        # ç»“æœè§£é‡Šéƒ¨åˆ†
        if self.analysis_state['interpretation']:
            report_sections.append("## ğŸ“ ç»“æœè§£é‡Š\n")
            interpretation = self.analysis_state['interpretation']
            report_sections.append("ç»“æœè§£é‡ŠæŒ‡å¯¼å·²ç”Ÿæˆï¼Œè¯·å‚è€ƒè§£é‡Šæç¤ºè¯è¿›è¡Œæ·±åº¦åˆ†æã€‚\n")
        
        # ç”ŸæˆæŠ¥å‘Š
        report = "\n".join(report_sections)
        
        # ä¿å­˜æŠ¥å‘Š
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        return report


def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # è®¾ç½®æŠ€èƒ½æ ¹ç›®å½•
    skill_root = "D:/stigmergy-CLI-Multi-Agents/sscisubagent-skills/msqca-analysis"
    
    # åˆå§‹åŒ–é›†æˆåˆ†æå™¨
    analyzer = IntegratedQCAAnalyzer(skill_root)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    sample_data = pd.DataFrame({
        'case_id': range(1, 21),
        'A': np.random.choice([0, 1, 2], 20),
        'B': np.random.choice([0, 1, 2], 20),
        'C': np.random.choice([0, 1, 2], 20),
        'Y': np.random.uniform(0, 1, 20)
    })
    
    print("ğŸš€ å¼€å§‹msQCAé›†æˆåˆ†æ...")
    
    # ç¬¬ä¸€æ­¥ï¼šç†è®ºåˆ†æ
    research_context = {
        'research_question': 'ä»€ä¹ˆæ¡ä»¶ç»„åˆå¯¼è‡´é«˜ç»©æ•ˆï¼Ÿ',
        'theoretical_framework': 'èµ„æºåŸºç¡€è§‚',
        'case_description': '20ä¸ªç»„ç»‡æ¡ˆä¾‹'
    }
    
    theoretical_analysis = analyzer.execute_theoretical_analysis(research_context)
    
    # ç¬¬äºŒæ­¥ï¼šæ ¡å‡†æŒ‡å¯¼
    calibration_plan = analyzer.execute_calibration_guidance(
        sample_data, theoretical_analysis
    )
    
    # ç¬¬ä¸‰æ­¥ï¼šå®šé‡åˆ†æ
    conditions = ['A', 'B', 'C']
    outcome = 'Y'
    
    quantitative_results = analyzer.execute_quantitative_analysis(
        sample_data, conditions, outcome, calibration_plan
    )
    
    # ç¬¬å››æ­¥ï¼šç»“æœè§£é‡Š
    interpretation = analyzer.execute_result_interpretation(
        quantitative_results, theoretical_analysis
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_analysis_report("integrated_analysis_report.md")
    
    print("âœ… msQCAé›†æˆåˆ†æå®Œæˆï¼")
    print(f"åˆ†æé˜¶æ®µ: {analyzer.analysis_state['phase']}")
    print("è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹å„é˜¶æ®µçš„æç¤ºè¯æŒ‡å¯¼è¿›è¡Œæ·±åº¦åˆ†æã€‚")


if __name__ == "__main__":
    main()