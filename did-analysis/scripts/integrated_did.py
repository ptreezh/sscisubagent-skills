#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DIDé›†æˆåˆ†æè„šæœ¬ - è®¡é‡ç†è®ºã€ç»Ÿè®¡æ–¹æ³•ã€æ”¿ç­–å®è·µä¸æ•°æ®ç§‘å­¦çš„å®Œç¾ç»“åˆ
æ ¹æ®AIåˆ†æå†³ç­–ï¼Œè°ƒç”¨ç›¸åº”çš„å®šæ€§æç¤ºè¯å’Œå®šé‡ç®—æ³•
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import json
import os
from pathlib import Path
import warnings

# å¯¼å…¥å®šé‡åˆ†ææ¨¡å—
from did_estimator import DIDEstimator
from parallel_trend import ParallelTrendTester
from robustness_test import RobustnessTester
from visualization import DIDVisualizer


class IntegratedDIDAnalyzer:
    """é›†æˆDIDåˆ†æå™¨ - ç†è®ºä¸å®è·µçš„å®Œç¾ç»“åˆ"""
    
    def __init__(self, skill_root: str):
        self.skill_root = Path(skill_root)
        self.prompts_dir = self.skill_root / "prompts"
        self.scripts_dir = self.skill_root / "scripts"
        self.references_dir = self.skill_root / "references"
        
        # åˆå§‹åŒ–å®šé‡åˆ†æç»„ä»¶
        self.estimator = DIDEstimator()
        self.trend_tester = ParallelTrendTester()
        self.robustness_tester = RobustnessTester()
        self.visualizer = DIDVisualizer()
        
        # åˆ†æçŠ¶æ€è·Ÿè¸ª
        self.analysis_state = {
            'phase': 'initiated',
            'experimental_design': None,
            'model_specification': None,
            'estimation_results': None,
            'causal_interpretation': None,
            'policy_recommendations': None
        }
    
    def load_prompt_content(self, prompt_name: str) -> str:
        """åŠ è½½æç¤ºè¯å†…å®¹"""
        prompt_file = self.prompts_dir / f"{prompt_name}.md"
        if not prompt_file.exists():
            raise FileNotFoundError(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    
    def execute_experimental_design(self, 
                                  policy_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®éªŒè®¾è®¡é˜¶æ®µ
        
        è¿™ä¸ªæ–¹æ³•ä¼šåŠ è½½å®éªŒè®¾è®¡æç¤ºè¯ï¼ŒæŒ‡å¯¼AIè¿›è¡Œæ·±åº¦æ”¿ç­–æœºåˆ¶åˆ†æ
        """
        print("ğŸ¯ å¼€å§‹å®éªŒè®¾è®¡é˜¶æ®µ...")
        
        # åŠ è½½å®éªŒè®¾è®¡æç¤ºè¯
        design_prompt = self.load_prompt_content("experimental-design")
        
        # æ„å»ºå®éªŒè®¾è®¡æŒ‡å¯¼
        design_guidance = {
            'prompt_content': design_prompt,
            'policy_context': policy_context,
            'design_focus': [
                'policy_mechanism',
                'group_selection', 
                'time_window',
                'treatment_intensity'
            ],
            'output_requirements': {
                'mechanism_analysis': 'æ”¿ç­–ä½œç”¨æœºåˆ¶åˆ†æ',
                'group_selection_plan': 'å®éªŒç»„å¯¹ç…§ç»„é€‰æ‹©æ–¹æ¡ˆ',
                'time_window_design': 'æ—¶é—´çª—å£è®¾è®¡',
                'variable_specification': 'å˜é‡è®¾å®šæ–¹æ¡ˆ'
            }
        }
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'experimental_design'
        self.analysis_state['experimental_design'] = design_guidance
        
        return design_guidance
    
    def execute_model_specification(self,
                                  data: pd.DataFrame,
                                  experimental_design: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¨¡å‹è®¾å®šé˜¶æ®µ
        
        ç»“åˆå®éªŒè®¾è®¡å’Œæ•°æ®ç‰¹å¾ï¼Œåˆ¶å®šDIDæ¨¡å‹è®¾å®šæ–¹æ¡ˆ
        """
        print("ğŸ“Š åˆ¶å®šDIDæ¨¡å‹è®¾å®š...")
        
        # åŠ è½½æ¨¡å‹è®¾å®šæç¤ºè¯
        specification_prompt = self.load_prompt_content("model-specification")
        
        # æ•°æ®ç‰¹å¾åˆ†æ
        data_characteristics = self._analyze_panel_data_characteristics(data)
        
        # æ„å»ºæ¨¡å‹è®¾å®šæŒ‡å¯¼
        specification_guidance = {
            'prompt_content': specification_prompt,
            'data_characteristics': data_characteristics,
            'experimental_design': experimental_design,
            'model_specifications': {},
            'identification_strategy': {}
        }
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹ç±»å‹è®¾å®šå…·ä½“æ–¹æ¡ˆ
        model_types = ['twoway_fe', 'event_study', 'synthetic_control', 'heterogeneous_effects']
        
        for model_type in model_types:
            model_spec = self._create_model_specification(
                model_type, data, data_characteristics, experimental_design
            )
            specification_guidance['model_specifications'][model_type] = model_spec
        
        # åˆ¶å®šå› æœè¯†åˆ«ç­–ç•¥
        specification_guidance['identification_strategy'] = self._create_identification_strategy(
            data_characteristics, experimental_design
        )
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'model_specification'
        self.analysis_state['model_specification'] = specification_guidance
        
        return specification_guidance
    
    def execute_did_estimation(self,
                              data: pd.DataFrame,
                              entity_col: str,
                              time_col: str,
                              treatment_col: str,
                              outcome_col: str,
                              model_specification: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒDIDä¼°è®¡é˜¶æ®µ
        
        æ ¹æ®æ¨¡å‹è®¾å®šæ‰§è¡Œå…·ä½“çš„è®¡é‡ä¼°è®¡
        """
        print("ğŸ”¬ æ‰§è¡ŒDIDè®¡é‡ä¼°è®¡...")
        
        # ç¬¬ä¸€æ­¥ï¼šå¹³è¡Œè¶‹åŠ¿æ£€éªŒ
        print("  - æ‰§è¡Œå¹³è¡Œè¶‹åŠ¿æ£€éªŒ...")
        parallel_trend_results = self.trend_tester.test_parallel_trend(
            data, entity_col, time_col, treatment_col, outcome_col
        )
        
        # ç¬¬äºŒæ­¥ï¼šåŸºç¡€DIDä¼°è®¡
        print("  - ä¼°è®¡åŸºç¡€DIDæ¨¡å‹...")
        control_vars = model_specification.get('control_variables', [])
        twoway_results = self.estimator.estimate_twoway_fe(
            data, entity_col, time_col, treatment_col, outcome_col, control_vars
        )
        
        # ç¬¬ä¸‰æ­¥ï¼šäº‹ä»¶ç ”ç©¶ä¼°è®¡
        print("  - ä¼°è®¡äº‹ä»¶ç ”ç©¶æ¨¡å‹...")
        event_results = self.estimator.estimate_event_study(
            data, entity_col, time_col, treatment_col, outcome_col, control_vars
        )
        
        # ç¬¬å››æ­¥ï¼šå¼‚è´¨æ€§æ•ˆåº”åˆ†æ
        print("  - åˆ†æå¼‚è´¨æ€§æ•ˆåº”...")
        heterogeneity_vars = model_specification.get('heterogeneity_vars', [])
        het_results = {}
        if heterogeneity_vars:
            het_results = self.estimator.estimate_heterogeneous_effects(
                data, entity_col, time_col, treatment_col, outcome_col, heterogeneity_vars, control_vars
            )
        
        # ç¬¬äº”æ­¥ï¼šç¨³å¥æ€§æ£€éªŒ
        print("  - æ‰§è¡Œç¨³å¥æ€§æ£€éªŒ...")
        robustness_results = self.robustness_tester.run_robustness_tests(
            data, entity_col, time_col, treatment_col, outcome_col, twoway_results
        )
        
        # æ•´åˆä¼°è®¡ç»“æœ
        estimation_results = {
            'parallel_trend_test': parallel_trend_results,
            'twoway_fe': twoway_results,
            'event_study': event_results,
            'heterogeneous_effects': het_results,
            'robustness_tests': robustness_results,
            'data_summary': self._summarize_data(data, entity_col, time_col, treatment_col, outcome_col),
            'quality_metrics': self._calculate_estimation_quality(
                parallel_trend_results, twoway_results, robustness_results
            )
        }
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'did_estimation'
        self.analysis_state['estimation_results'] = estimation_results
        
        return estimation_results
    
    def execute_causal_interpretation(self,
                                    estimation_results: Dict[str, Any],
                                    experimental_design: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå› æœè§£é‡Šé˜¶æ®µ
        
        åŠ è½½å› æœè§£é‡Šæç¤ºè¯ï¼ŒæŒ‡å¯¼AIè¿›è¡Œæ·±åº¦å› æœæœºåˆ¶é˜é‡Š
        """
        print("ğŸ“ æ·±åº¦è§£é‡Šå› æœæ•ˆåº”...")
        
        # åŠ è½½å› æœè§£é‡Šæç¤ºè¯
        interpretation_prompt = self.load_prompt_content("causal-interpretation")
        
        # å‡†å¤‡è§£é‡Šæ‰€éœ€çš„ä¿¡æ¯
        interpretation_context = {
            'prompt_content': interpretation_prompt,
            'estimation_results': estimation_results,
            'experimental_design': experimental_design,
            'interpretation_focus': [
                'effect_size_interpretation',
                'causal_mechanism',
                'parallel_trend_assessment',
                'robustness_evaluation',
                'policy_implications'
            ]
        }
        
        # ç”Ÿæˆè§£é‡ŠæŒ‡å¯¼
        interpretation_guidance = self._create_interpretation_guidance(
            estimation_results, experimental_design
        )
        
        interpretation_context['interpretation_guidance'] = interpretation_guidance
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'causal_interpretation'
        self.analysis_state['causal_interpretation'] = interpretation_context
        
        return interpretation_context
    
    def execute_policy_recommendations(self,
                                     causal_interpretation: Dict[str, Any],
                                     policy_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ”¿ç­–å»ºè®®é˜¶æ®µ
        
        åŸºäºå› æœè§£é‡Šå’Œæ”¿ç­–èƒŒæ™¯åˆ¶å®šæ”¿ç­–å»ºè®®
        """
        print("ğŸ¯ åˆ¶å®šæ”¿ç­–å»ºè®®...")
        
        # åŠ è½½æ”¿ç­–å»ºè®®æç¤ºè¯
        recommendation_prompt = self.load_prompt_content("policy-recommendation")
        
        # æ„å»ºæ”¿ç­–å»ºè®®æŒ‡å¯¼
        recommendation_context = {
            'prompt_content': recommendation_prompt,
            'causal_interpretation': causal_interpretation,
            'policy_context': policy_context,
            'recommendation_types': [
                'policy_continuation',
                'policy_optimization',
                'policy_expansion',
                'policy_innovation'
            ]
        }
        
        # ç”Ÿæˆæ”¿ç­–å»ºè®®æŒ‡å¯¼
        recommendation_guidance = self._create_policy_recommendation_guidance(
            causal_interpretation, policy_context
        )
        
        recommendation_context['recommendation_guidance'] = recommendation_guidance
        
        # æ›´æ–°åˆ†æçŠ¶æ€
        self.analysis_state['phase'] = 'policy_recommendations'
        self.analysis_state['policy_recommendations'] = recommendation_context
        
        return recommendation_context
    
    def _analyze_panel_data_characteristics(self, data: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æé¢æ¿æ•°æ®ç‰¹å¾"""
        characteristics = {}
        
        # åŸºæœ¬æ•°æ®ç»“æ„
        characteristics['data_structure'] = {
            'n_rows': len(data),
            'n_columns': len(data.columns),
            'memory_usage': data.memory_usage(deep=True).sum()
        }
        
        # é¢æ¿æ•°æ®ç‰¹å¾
        entity_col = data.select_dtypes(include=['object']).columns[0] if len(data.select_dtypes(include=['object']).columns) > 0 else None
        time_col = data.select_dtypes(include=['int64', 'float64']).columns[0] if len(data.select_dtypes(include=['int64', 'float64']).columns) > 0 else None
        
        if entity_col and time_col:
            characteristics['panel_structure'] = {
                'n_entities': data[entity_col].nunique(),
                'n_periods': data[time_col].nunique(),
                'balance_ratio': len(data) / (data[entity_col].nunique() * data[time_col].nunique()),
                'time_span': [data[time_col].min(), data[time_col].max()]
            }
        
        # å˜é‡ç‰¹å¾
        characteristics['variable_characteristics'] = {}
        for col in data.columns:
            if data[col].dtype in ['int64', 'float64']:
                characteristics['variable_characteristics'][col] = {
                    'dtype': 'numeric',
                    'missing_rate': data[col].isna().sum() / len(data),
                    'mean': data[col].mean(),
                    'std': data[col].std(),
                    'min': data[col].min(),
                    'max': data[col].max()
                }
            else:
                characteristics['variable_characteristics'][col] = {
                    'dtype': 'categorical',
                    'missing_rate': data[col].isna().sum() / len(data),
                    'n_unique': data[col].nunique(),
                    'most_frequent': data[col].mode().iloc[0] if len(data[col].mode()) > 0 else None
                }
        
        return characteristics
    
    def _create_model_specification(self,
                                  model_type: str,
                                  data: pd.DataFrame,
                                  data_characteristics: Dict[str, Any],
                                  experimental_design: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸ºç‰¹å®šæ¨¡å‹ç±»å‹åˆ›å»ºè®¾å®šæ–¹æ¡ˆ"""
        spec = {
            'model_type': model_type,
            'suitability': self._assess_model_suitability(model_type, data_characteristics),
            'specification_details': {},
            'identification_assumptions': [],
            'data_requirements': {}
        }
        
        if model_type == 'twoway_fe':
            spec['specification_details'] = {
                'entity_effects': True,
                'time_effects': True,
                'interaction_term': 'treatment * post',
                'control_variables': experimental_design.get('control_variables', [])
            }
            spec['identification_assumptions'] = [
                'å¹³è¡Œè¶‹åŠ¿å‡è®¾',
                'æ— é¢„æœŸæ•ˆåº”',
                'SUTVAå‡è®¾'
            ]
            
        elif model_type == 'event_study':
            spec['specification_details'] = {
                'event_time_dummies': True,
                'reference_period': -1,
                'dynamic_effects': True,
                'leads_and_lags': True
            }
            spec['identification_assumptions'] = [
                'å¹³è¡Œè¶‹åŠ¿å‡è®¾',
                'æ— é¢„æœŸæ•ˆåº”',
                'æ•ˆåº”çº¿æ€§æ€§'
            ]
            
        elif model_type == 'synthetic_control':
            spec['specification_details'] = {
                'treated_unit': experimental_design.get('treated_entity'),
                'donor_pool': experimental_design.get('control_entities'),
                'pre_treatment_periods': experimental_design.get('pre_period_length'),
                'optimization_method': 'least_squares'
            }
            spec['identification_assumptions'] = [
                'åˆæˆæ§åˆ¶æƒé‡éè´Ÿ',
                'æƒé‡å’Œä¸º1',
                'æ— æœªè§‚æµ‹å› ç´ å¹²æ‰°'
            ]
            
        elif model_type == 'heterogeneous_effects':
            spec['specification_details'] = {
                'heterogeneity_vars': experimental_design.get('heterogeneity_vars', []),
                'interaction_terms': True,
                'subgroup_analysis': True
            }
            spec['identification_assumptions'] = [
                'å¹³è¡Œè¶‹åŠ¿å‡è®¾åœ¨å„ç»„æˆç«‹',
                'å¼‚è´¨æ€§å¤–ç”Ÿæ€§'
            ]
        
        return spec
    
    def _assess_model_suitability(self, model_type: str, data_characteristics: Dict[str, Any]) -> str:
        """è¯„ä¼°æ¨¡å‹é€‚åˆæ€§"""
        if 'panel_structure' not in data_characteristics:
            return 'unknown'
        
        n_entities = data_characteristics['panel_structure']['n_entities']
        n_periods = data_characteristics['panel_structure']['n_periods']
        balance_ratio = data_characteristics['panel_structure']['balance_ratio']
        
        if model_type == 'twoway_fe':
            if n_entities >= 10 and n_periods >= 3 and balance_ratio > 0.7:
                return 'highly_suitable'
            elif n_entities >= 5 and n_periods >= 2:
                return 'moderately_suitable'
            else:
                return 'not_suitable'
                
        elif model_type == 'event_study':
            if n_periods >= 5 and balance_ratio > 0.8:
                return 'highly_suitable'
            elif n_periods >= 3:
                return 'moderately_suitable'
            else:
                return 'not_suitable'
                
        elif model_type == 'synthetic_control':
            if n_entities >= 20 and n_periods >= 5:
                return 'highly_suitable'
            elif n_entities >= 10 and n_periods >= 3:
                return 'moderately_suitable'
            else:
                return 'not_suitable'
                
        elif model_type == 'heterogeneous_effects':
            if n_entities >= 20:
                return 'highly_suitable'
            elif n_entities >= 10:
                return 'moderately_suitable'
            else:
                return 'not_suitable'
        
        return 'unknown'
    
    def _create_identification_strategy(self,
                                      data_characteristics: Dict[str, Any],
                                      experimental_design: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå› æœè¯†åˆ«ç­–ç•¥"""
        strategy = {
            'primary_strategy': 'difference_in_differences',
            'identification_assumptions': [],
            'threats_to_identification': [],
            'mitigation_strategies': []
        }
        
        # åŸºæœ¬DIDå‡è®¾
        strategy['identification_assumptions'] = [
            'å¹³è¡Œè¶‹åŠ¿å‡è®¾',
            'æ— é¢„æœŸæ•ˆåº”',
            'å¤„ç†å¤–ç”Ÿæ€§',
            'ç¨³å®šå•ä½å¤„ç†å€¼å‡è®¾(SUTVA)',
            'æ— åŒæ—¶æœŸå…¶ä»–æ”¿ç­–å¹²é¢„'
        ]
        
        # è¯†åˆ«å¨èƒ
        strategy['threats_to_identification'] = [
            'å¤„ç†ç»„å’Œå¯¹ç…§ç»„è¶‹åŠ¿å·®å¼‚',
            'é¢„æœŸæ•ˆåº”å­˜åœ¨',
            'å¤„ç†å†…ç”Ÿæ€§',
            'åŒæ—¶æœŸæ”¿ç­–å¹²æ‰°',
            'æµ‹é‡è¯¯å·®'
        ]
        
        # ç¼“è§£ç­–ç•¥
        strategy['mitigation_strategies'] = [
            'å¹³è¡Œè¶‹åŠ¿æ£€éªŒ',
            'äº‹ä»¶ç ”ç©¶åˆ†æ',
            'å·¥å…·å˜é‡æ³•',
            'å®‰æ…°å‰‚æ£€éªŒ',
            'ç¨³å¥æ€§æ£€éªŒ'
        ]
        
        return strategy
    
    def _summarize_data(self, data: pd.DataFrame, entity_col: str, time_col: str, 
                        treatment_col: str, outcome_col: str) -> Dict[str, Any]:
        """æ€»ç»“æ•°æ®ç‰¹å¾"""
        summary = {}
        
        # å¤„ç†ç»„ç»Ÿè®¡
        treated_data = data[data[treatment_col] == 1]
        control_data = data[data[treatment_col] == 0]
        
        summary['treatment_stats'] = {
            'n_treated_entities': treated_data[entity_col].nunique(),
            'n_control_entities': control_data[entity_col].nunique(),
            'treatment_rate': len(treated_data) / len(data),
            'outcome_mean_treated': treated_data[outcome_col].mean(),
            'outcome_mean_control': control_data[outcome_col].mean()
        }
        
        # æ—¶é—´è¶‹åŠ¿
        time_trends = data.groupby([time_col, treatment_col])[outcome_col].mean().unstack()
        summary['time_trends'] = time_trends.to_dict()
        
        return summary
    
    def _calculate_estimation_quality(self,
                                    parallel_trend_results: Dict[str, Any],
                                    twoway_results: Dict[str, Any],
                                    robustness_results: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ä¼°è®¡è´¨é‡æŒ‡æ ‡"""
        quality = {}
        
        # å¹³è¡Œè¶‹åŠ¿æ£€éªŒè´¨é‡
        if 'parallel_trend_pvalue' in parallel_trend_results:
            quality['parallel_trend'] = {
                'assumption_met': parallel_trend_results['parallel_trend_pvalue'] > 0.05,
                'p_value': parallel_trend_results['parallel_trend_pvalue'],
                'confidence': 'high' if parallel_trend_results['parallel_trend_pvalue'] > 0.1 else 'medium'
            }
        
        # DIDä¼°è®¡è´¨é‡
        quality['did_estimation'] = {
            'statistical_significance': twoway_results['did_pvalue'] < 0.05,
            'effect_size': abs(twoway_results['did_effect']),
            'precision': twoway_results['did_se'] / abs(twoway_results['did_effect']),
            'model_fit': twoway_results['r_squared']
        }
        
        # ç¨³å¥æ€§è´¨é‡
        if 'placebo_pvalue' in robustness_results:
            quality['robustness'] = {
                'placebo_test_passed': robustness_results['placebo_pvalue'] < 0.05,
                'sensitivity_analysis': 'stable' if robustness_results.get('sensitivity_stable', False) else 'unstable'
            }
        
        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_scores = []
        if 'parallel_trend' in quality:
            quality_scores.append(1.0 if quality['parallel_trend']['assumption_met'] else 0.5)
        if 'did_estimation' in quality:
            quality_scores.append(min(1.0, quality['did_estimation']['model_fit'] * 2))
        if 'robustness' in quality:
            quality_scores.append(1.0 if quality['robustness']['placebo_test_passed'] else 0.5)
        
        quality['overall_quality'] = np.mean(quality_scores) if quality_scores else 0.5
        
        return quality
    
    def _create_interpretation_guidance(self,
                                      estimation_results: Dict[str, Any],
                                      experimental_design: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå› æœè§£é‡ŠæŒ‡å¯¼"""
        guidance = {
            'effect_interpretation': {},
            'mechanism_analysis': {},
            'robustness_assessment': {},
            'interpretation_questions': []
        }
        
        # æ•ˆåº”è§£é‡ŠæŒ‡å¯¼
        if 'twoway_fe' in estimation_results:
            did_results = estimation_results['twoway_fe']
            guidance['effect_interpretation'] = {
                'point_estimate': did_results['did_effect'],
                'confidence_interval': [did_results['did_ci_lower'], did_results['did_ci_upper']],
                'statistical_significance': did_results['did_pvalue'],
                'economic_significance': self._assess_economic_significance(did_results),
                'interpretation_focus': [
                    'æ•ˆåº”å¤§å°çš„å®é™…å«ä¹‰',
                    'ç½®ä¿¡åŒºé—´çš„æ”¿ç­–å«ä¹‰',
                    'ç»Ÿè®¡æ˜¾è‘—æ€§ä¸å®é™…æ„ä¹‰çš„å…³ç³»'
                ]
            }
        
        # æœºåˆ¶åˆ†ææŒ‡å¯¼
        guidance['mechanism_analysis'] = {
            'parallel_trend_status': estimation_results.get('parallel_trend_test', {}),
            'dynamic_effects': estimation_results.get('event_study', {}),
            'heterogeneity_patterns': estimation_results.get('heterogeneous_effects', {}),
            'analysis_questions': [
                'æ”¿ç­–é€šè¿‡ä»€ä¹ˆæ¸ é“äº§ç”Ÿæ•ˆåº”ï¼Ÿ',
                'æ•ˆåº”æ˜¯å¦éšæ—¶é—´å˜åŒ–ï¼Ÿ',
                'ä¸åŒç¾¤ä½“çš„æ•ˆåº”å·®å¼‚å¦‚ä½•è§£é‡Šï¼Ÿ'
            ]
        }
        
        # ç¨³å¥æ€§è¯„ä¼°æŒ‡å¯¼
        guidance['robustness_assessment'] = {
            'robustness_results': estimation_results.get('robustness_tests', {}),
            'quality_metrics': estimation_results.get('quality_metrics', {}),
            'assessment_criteria': [
                'å¹³è¡Œè¶‹åŠ¿å‡è®¾æ˜¯å¦æ»¡è¶³ï¼Ÿ',
                'å®‰æ…°å‰‚æ£€éªŒæ˜¯å¦é€šè¿‡ï¼Ÿ',
                'ä¸åŒæ¨¡å‹è®¾å®šçš„ç»“æœæ˜¯å¦ä¸€è‡´ï¼Ÿ'
            ]
        }
        
        # è§£é‡Šé—®é¢˜
        guidance['interpretation_questions'] = [
            "ä¼°è®¡çš„å› æœæ•ˆåº”åœ¨ç†è®ºå’Œå®è·µä¸Šæ„å‘³ç€ä»€ä¹ˆï¼Ÿ",
            "å¹³è¡Œè¶‹åŠ¿å‡è®¾çš„æ»¡è¶³ç¨‹åº¦å¦‚ä½•å½±å“å› æœæ¨æ–­çš„å¯é æ€§ï¼Ÿ",
            "å¼‚è´¨æ€§æ•ˆåº”æ­ç¤ºçš„æ”¿ç­–å«ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ç¨³å¥æ€§æ£€éªŒç»“æœå¯¹å› æœæ¨æ–­çš„ä¿¡å¿ƒæœ‰ä½•å½±å“ï¼Ÿ",
            "ç ”ç©¶ç»“æœå¯¹æ”¿ç­–åˆ¶å®šæœ‰ä»€ä¹ˆå…·ä½“æŒ‡å¯¼æ„ä¹‰ï¼Ÿ"
        ]
        
        return guidance
    
    def _assess_economic_significance(self, did_results: Dict[str, Any]) -> str:
        """è¯„ä¼°ç»æµæ˜¾è‘—æ€§"""
        effect_size = abs(did_results['did_effect'])
        
        # ç®€åŒ–çš„ç»æµæ˜¾è‘—æ€§è¯„ä¼°ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦å…·ä½“é¢†åŸŸçŸ¥è¯†ï¼‰
        if effect_size > 10:
            return 'large'
        elif effect_size > 5:
            return 'medium'
        elif effect_size > 1:
            return 'small'
        else:
            return 'minimal'
    
    def _create_policy_recommendation_guidance(self,
                                             causal_interpretation: Dict[str, Any],
                                             policy_context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæ”¿ç­–å»ºè®®æŒ‡å¯¼"""
        guidance = {
            'effectiveness_assessment': {},
            'recommendation_types': {},
            'implementation_considerations': {},
            'risk_assessment': {}
        }
        
        # æœ‰æ•ˆæ€§è¯„ä¼°
        if 'estimation_results' in causal_interpretation:
            estimation = causal_interpretation['estimation_results']
            guidance['effectiveness_assessment'] = {
                'policy_effectiveness': self._assess_policy_effectiveness(estimation),
                'cost_benefit_considerations': self._generate_cost_benefit_considerations(estimation),
                'target_group_benefits': self._identify_target_group_benefits(estimation)
            }
        
        # å»ºè®®ç±»å‹
        guidance['recommendation_types'] = {
            'continuation': {
                'condition': 'effect_positive_and_significant',
                'rationale': 'æ”¿ç­–äº§ç”Ÿäº†é¢„æœŸæ•ˆæœ'
            },
            'optimization': {
                'condition': 'effect_moderate_or_heterogeneous',
                'rationale': 'æ”¿ç­–æœ‰æ”¹è¿›ç©ºé—´'
            },
            'expansion': {
                'condition': 'effect_large_and_robust',
                'rationale': 'æ”¿ç­–æ•ˆæœæ˜¾è‘—ä¸”ç¨³å¥'
            },
            'termination': {
                'condition': 'effect_negative_or_insignificant',
                'rationale': 'æ”¿ç­–æœªäº§ç”Ÿé¢„æœŸæ•ˆæœ'
            }
        }
        
        # å®æ–½è€ƒè™‘
        guidance['implementation_considerations'] = {
            'scalability': 'æ”¿ç­–æ˜¯å¦å¯ä»¥æ‰©å¤§è§„æ¨¡ï¼Ÿ',
            'resource_requirements': 'å®æ–½æ”¿ç­–éœ€è¦ä»€ä¹ˆèµ„æºï¼Ÿ',
            'institutional_capacity': 'æ˜¯å¦æœ‰è¶³å¤Ÿçš„åˆ¶åº¦èƒ½åŠ›ï¼Ÿ',
            'political_feasibility': 'æ”¿æ²»ä¸Šæ˜¯å¦å¯è¡Œï¼Ÿ'
        }
        
        # é£é™©è¯„ä¼°
        guidance['risk_assessment'] = {
            'external_validity': 'ç»“æœæ˜¯å¦å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–æƒ…å¢ƒï¼Ÿ',
            'unintended_consequences': 'æ˜¯å¦å­˜åœ¨æ½œåœ¨çš„è´Ÿé¢æ•ˆåº”ï¼Ÿ',
            'sustainability': 'æ”¿ç­–æ•ˆæœæ˜¯å¦å¯æŒç»­ï¼Ÿ',
            'equity_implications': 'æ”¿ç­–å¯¹ä¸åŒç¾¤ä½“çš„å½±å“æ˜¯å¦å…¬å¹³ï¼Ÿ'
        }
        
        return guidance
    
    def _assess_policy_effectiveness(self, estimation_results: Dict[str, Any]) -> str:
        """è¯„ä¼°æ”¿ç­–æœ‰æ•ˆæ€§"""
        if 'twoway_fe' not in estimation_results:
            return 'unknown'
        
        did_results = estimation_results['twoway_fe']
        effect = did_results['did_effect']
        pvalue = did_results['did_pvalue']
        
        if pvalue < 0.05 and effect > 0:
            return 'effective'
        elif pvalue < 0.05 and effect < 0:
            return 'counterproductive'
        elif pvalue >= 0.05:
            return 'ineffective'
        else:
            return 'unclear'
    
    def _generate_cost_benefit_considerations(self, estimation_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæˆæœ¬æ•ˆç›Šè€ƒè™‘"""
        return [
            "æ”¿ç­–å®æ–½æˆæœ¬ä¸æ•ˆåº”å¤§å°çš„æ¯”è¾ƒ",
            "é•¿æœŸæ•ˆåº”ä¸çŸ­æœŸæ•ˆåº”çš„æƒè¡¡",
            "ç›´æ¥æ•ˆåº”ä¸é—´æ¥æ•ˆåº”çš„ç»¼åˆè¯„ä¼°",
            "å¯é‡åŒ–æ”¶ç›Šä¸ä¸å¯é‡åŒ–æ”¶ç›Šçš„å¹³è¡¡"
        ]
    
    def _identify_target_group_benefits(self, estimation_results: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«ç›®æ ‡ç¾¤ä½“æ”¶ç›Š"""
        benefits = []
        
        if 'heterogeneous_effects' in estimation_results:
            het_results = estimation_results['heterogeneous_effects']
            for var, effects in het_results.items():
                if 'group_effects' in effects:
                    for group, effect in effects['group_effects'].items():
                        if effect > 0:
                            benefits.append(f"{var}={group}ç¾¤ä½“: æ­£é¢æ•ˆåº”")
        
        return benefits
    
    def generate_comprehensive_report(self, output_file: str = None) -> str:
        """ç”Ÿæˆå®Œæ•´çš„DIDåˆ†ææŠ¥å‘Š"""
        report_sections = []
        
        # æŠ¥å‘Šæ ‡é¢˜
        report_sections.append("# DIDå› æœæ¨æ–­åˆ†ææŠ¥å‘Š\n")
        
        # å®éªŒè®¾è®¡éƒ¨åˆ†
        if self.analysis_state['experimental_design']:
            report_sections.append("## ğŸ¯ å®éªŒè®¾è®¡\n")
            report_sections.append("å®éªŒè®¾è®¡å·²å®Œæˆï¼Œè¯¦è§å®éªŒè®¾è®¡æŒ‡å¯¼æ–‡æ¡£ã€‚\n")
        
        # æ¨¡å‹è®¾å®šéƒ¨åˆ†
        if self.analysis_state['model_specification']:
            report_sections.append("## ğŸ“Š æ¨¡å‹è®¾å®š\n")
            model_spec = self.analysis_state['model_specification']
            report_sections.append("æ¨¡å‹è®¾å®šæ–¹æ¡ˆå·²åˆ¶å®šï¼ŒåŒ…å«å¤šç§DIDä¼°è®¡æ–¹æ³•ã€‚\n")
        
        # ä¼°è®¡ç»“æœéƒ¨åˆ†
        if self.analysis_state['estimation_results']:
            report_sections.append("## ğŸ”¬ DIDä¼°è®¡ç»“æœ\n")
            results = self.analysis_state['estimation_results']
            
            report_sections.append("### ä¸»è¦ä¼°è®¡ç»“æœ\n")
            if 'twoway_fe' in results:
                did = results['twoway_fe']
                report_sections.append(f"- DIDæ•ˆåº”: {did['did_effect']:.4f} (p={did['did_pvalue']:.4f})\n")
                report_sections.append(f"- 95%ç½®ä¿¡åŒºé—´: [{did['did_ci_lower']:.4f}, {did['did_ci_upper']:.4f}]\n")
                report_sections.append(f"- RÂ²: {did['r_squared']:.4f}\n")
            
            report_sections.append("### å¹³è¡Œè¶‹åŠ¿æ£€éªŒ\n")
            if 'parallel_trend_test' in results:
                pt = results['parallel_trend_test']
                if 'parallel_trend_pvalue' in pt:
                    report_sections.append(f"- å¹³è¡Œè¶‹åŠ¿æ£€éªŒpå€¼: {pt['parallel_trend_pvalue']:.4f}\n")
            
            report_sections.append("### ç¨³å¥æ€§æ£€éªŒ\n")
            if 'robustness_tests' in results:
                rt = results['robustness_tests']
                if 'placebo_pvalue' in rt:
                    report_sections.append(f"- å®‰æ…°å‰‚æ£€éªŒpå€¼: {rt['placebo_pvalue']:.4f}\n")
        
        # å› æœè§£é‡Šéƒ¨åˆ†
        if self.analysis_state['causal_interpretation']:
            report_sections.append("## ğŸ“ å› æœè§£é‡Š\n")
            interpretation = self.analysis_state['causal_interpretation']
            report_sections.append("å› æœè§£é‡ŠæŒ‡å¯¼å·²ç”Ÿæˆï¼Œè¯·å‚è€ƒå› æœè§£é‡Šæç¤ºè¯è¿›è¡Œæ·±åº¦åˆ†æã€‚\n")
        
        # æ”¿ç­–å»ºè®®éƒ¨åˆ†
        if self.analysis_state['policy_recommendations']:
            report_sections.append("## ğŸ¯ æ”¿ç­–å»ºè®®\n")
            recommendations = self.analysis_state['policy_recommendations']
            report_sections.append("æ”¿ç­–å»ºè®®æŒ‡å¯¼å·²ç”Ÿæˆï¼Œè¯·å‚è€ƒæ”¿ç­–å»ºè®®æç¤ºè¯åˆ¶å®šå…·ä½“å»ºè®®ã€‚\n")
        
        # ç”ŸæˆæŠ¥å‘Š
        report = "\n".join(report_sections)
        
        # ä¿å­˜æŠ¥å‘Š
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"DIDåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        return report


def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # è®¾ç½®æŠ€èƒ½æ ¹ç›®å½•
    skill_root = "D:/stigmergy-CLI-Multi-Agents/sscisubagent-skills/did-analysis"
    
    # åˆå§‹åŒ–é›†æˆåˆ†æå™¨
    analyzer = IntegratedDIDAnalyzer(skill_root)
    
    # åˆ›å»ºç¤ºä¾‹é¢æ¿æ•°æ®
    np.random.seed(42)
    n_entities = 30
    n_periods = 8
    entities = [f"entity_{i}" for i in range(n_entities)]
    periods = list(range(2015, 2015 + n_periods))
    
    data = []
    for entity in entities:
        base_outcome = 100 + np.random.normal(0, 10)
        entity_fe = np.random.normal(0, 5)
        
        for period in periods:
            time_fe = (period - 2015) * 2
            treat = 0
            
            # å¤„ç†æ•ˆåº”
            if entity in ['entity_1', 'entity_2', 'entity_3'] and period >= 2018:
                treat = 1
                treatment_effect = 15
            else:
                treatment_effect = 0
            
            outcome = (base_outcome + entity_fe + time_fe + treatment_effect + 
                     np.random.normal(0, 5))
            
            data.append({
                'entity': entity,
                'year': period,
                'treatment': treat,
                'outcome': outcome,
                'control_var1': np.random.normal(0, 1),
                'control_var2': np.random.normal(0, 1)
            })
    
    df = pd.DataFrame(data)
    
    print("ğŸš€ å¼€å§‹DIDé›†æˆåˆ†æ...")
    
    # ç¬¬ä¸€æ­¥ï¼šå®éªŒè®¾è®¡
    policy_context = {
        'policy_name': 'æ•™è‚²è´¨é‡æå‡æ”¿ç­–',
        'policy_objective': 'æé«˜å­¦ç”Ÿå­¦ä¸šæˆç»©',
        'implementation_year': 2018,
        'target_population': 'ä¸­å°å­¦å­¦ç”Ÿ'
    }
    
    experimental_design = analyzer.execute_experimental_design(policy_context)
    
    # ç¬¬äºŒæ­¥ï¼šæ¨¡å‹è®¾å®š
    model_specification = analyzer.execute_model_specification(df, experimental_design)
    
    # ç¬¬ä¸‰æ­¥ï¼šDIDä¼°è®¡
    estimation_results = analyzer.execute_did_estimation(
        df, 'entity', 'year', 'treatment', 'outcome', model_specification
    )
    
    # ç¬¬å››æ­¥ï¼šå› æœè§£é‡Š
    causal_interpretation = analyzer.execute_causal_interpretation(
        estimation_results, experimental_design
    )
    
    # ç¬¬äº”æ­¥ï¼šæ”¿ç­–å»ºè®®
    policy_recommendations = analyzer.execute_policy_recommendations(
        causal_interpretation, policy_context
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_comprehensive_report("did_analysis_report.md")
    
    print("âœ… DIDé›†æˆåˆ†æå®Œæˆï¼")
    print(f"åˆ†æé˜¶æ®µ: {analyzer.analysis_state['phase']}")
    print("è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹å„é˜¶æ®µçš„æç¤ºè¯æŒ‡å¯¼è¿›è¡Œæ·±åº¦åˆ†æã€‚")


if __name__ == "__main__":
    main()
