# æŠ€èƒ½å®ç°æ ¸å¿ƒæ–¹æ³•è®º

**ç‰ˆæœ¬**: 1.0.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-12-18  
**åŸºäº**: sscisubagent-skillsæŠ€èƒ½åŒ…æ·±åº¦åˆ†æ

---

## æ ¸å¿ƒè®¤çŸ¥

### æŠ€èƒ½çš„æœ¬è´¨

**æŠ€èƒ½ = æç¤ºè¯(å®šæ€§) + è„šæœ¬(å®šé‡) + ä¸Šä¸‹æ–‡(å‚è€ƒ)**

```
æŠ€èƒ½æ˜¯å¯¹AIèƒ½åŠ›çš„æ‰©å±•ï¼Œæ˜¯æç¤ºè¯ã€ä¸Šä¸‹æ–‡å’Œè„šæœ¬ç¨‹åºçš„æ··åˆä½“ï¼š
- ç¡®å®šæ€§é€»è¾‘ â†’ ä»£ç åŒ–/è„šæœ¬åŒ–
- ç»¼åˆæ™ºèƒ½åˆ†æ â†’ æç¤ºè¯æŒ‡å¯¼
- è¯¦ç»†èƒŒæ™¯çŸ¥è¯† â†’ å‚è€ƒæ–‡æ¡£ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
```

### è®¾è®¡å“²å­¦

**æ¸è¿›å¼æŠ«éœ²åŸåˆ™**ï¼š
- ä¼˜åŒ–AIä¸Šä¸‹æ–‡è´Ÿè½½
- åªåœ¨å¿…è¦æ—¶åŠ è½½å¿…è¦æ–‡ä»¶
- é’ˆå¯¹åº”ç”¨åœºæ™¯åˆ†å±‚ç»„ç»‡

---

## åå¤§æ ¸å¿ƒåŸåˆ™

### 1. å®šæ€§å®šé‡ä¸¥æ ¼åˆ†ç¦»

**å®šæ€§éƒ¨åˆ†ï¼ˆSKILL.mdæç¤ºè¯ï¼‰**ï¼š
- âœ… æ¦‚å¿µå‘½ååŸåˆ™ï¼ˆå¦‚"å¯»æ±‚æ”¯æŒ"è€Œé"support_seeking"ï¼‰
- âœ… ç†è®ºè§£é‡Šï¼ˆå¦‚Paradigmæ¨¡å‹çš„é€»è¾‘ï¼‰
- âœ… è´¨é‡æ ‡å‡†ï¼ˆå¦‚é¥±å’Œåº¦åˆ¤æ–­æ ‡å‡†ï¼‰
- âœ… ä¸­æ–‡è¯­å¢ƒé€‚é…ï¼ˆå¦‚"å…³ç³»èµ„æœ¬"çš„æ–‡åŒ–å«ä¹‰ï¼‰
- âœ… æµç¨‹æŒ‡å¯¼ï¼ˆå¦‚"å…ˆè¯†åˆ«èŒƒç•´ï¼Œå†åˆ†æå±æ€§"ï¼‰

**å®šé‡éƒ¨åˆ†ï¼ˆscripts/è„šæœ¬ï¼‰**ï¼š
- âœ… æ–‡æœ¬é¢„å¤„ç†ï¼ˆjiebaåˆ†è¯ã€å»åœç”¨è¯ï¼‰
- âœ… èšç±»ç®—æ³•ï¼ˆK-meansã€å±‚æ¬¡èšç±»ï¼‰
- âœ… ç½‘ç»œè®¡ç®—ï¼ˆä¸­å¿ƒæ€§ã€ç¤¾åŒºå‘ç°ï¼‰
- âœ… ç»Ÿè®¡æ£€éªŒï¼ˆtæ£€éªŒã€å¡æ–¹æ£€éªŒã€å› å­åˆ†æï¼‰
- âœ… å¯è§†åŒ–ç”Ÿæˆï¼ˆç½‘ç»œå›¾ã€ç›´æ–¹å›¾ã€çƒ­åŠ›å›¾ï¼‰

**åæ¨¡å¼è­¦ç¤º**ï¼š
- âŒ åœ¨SKILL.mdä¸­å†™ç®—æ³•ä¼ªä»£ç ï¼ˆåº”è¯¥ç”¨è„šæœ¬ï¼‰
- âŒ åœ¨è„šæœ¬ä¸­ç¡¬ç¼–ç æ¦‚å¿µå‘½åè§„åˆ™ï¼ˆåº”è¯¥ç”¨æç¤ºè¯ï¼‰

---

### 2. ä¸‰å±‚ä¿¡æ¯æŠ«éœ²

**ç¬¬1å±‚ï¼šSKILL.mdæ ¸å¿ƒæç¤ºè¯ï¼ˆ5-10ç§’ç†è§£ï¼‰**
```markdown
---
name: performing-axial-coding
description: æ‰§è¡Œæ‰æ ¹ç†è®ºçš„è½´å¿ƒç¼–ç ï¼Œè¯†åˆ«èŒƒç•´ã€åˆ†æå±æ€§ã€å»ºç«‹å…³ç³»ã€‚å½“éœ€è¦å°†å¼€æ”¾ç¼–ç ç»“æœæ•´åˆä¸ºèŒƒç•´ä½“ç³»æ—¶ä½¿ç”¨ã€‚
---

## ä½¿ç”¨æ—¶æœº
- "è½´å¿ƒç¼–ç "
- "èŒƒç•´æ„å»º"
- "æ¦‚å¿µå½’ç±»"

## å¿«é€Ÿå·¥å…·
```bash
python scripts/identify_categories.py --input codes.json --output categories.json
```
```

**ç¬¬2å±‚ï¼šJSONè¾“å‡ºæ‘˜è¦ï¼ˆ30ç§’é˜…è¯»ï¼‰**
```json
{
  "summary": {
    "total_categories": 8,
    "key_categories": ["å­¦ä¹ æ”¯æŒ", "æƒ…æ„Ÿè°ƒèŠ‚", "ç›®æ ‡è®¾å®š"],
    "relationship_count": 12,
    "paradigm_identified": true
  }
}
```

**ç¬¬3å±‚ï¼šreferences/è¯¦ç»†æ–‡æ¡£ï¼ˆæŒ‰éœ€æ·±å…¥ï¼‰**
```markdown
# references/theory.md
## è½´å¿ƒç¼–ç çš„ç†è®ºåŸºç¡€
Strauss & Corbin (1998) æå‡ºçš„è½´å¿ƒç¼–ç ...
ï¼ˆè¯¦ç»†ç†è®ºèƒŒæ™¯ï¼Œ5000å­—ï¼‰
```

---

### 3. æ ‡å‡†åŒ–è„šæœ¬æ¥å£

**å‘½ä»¤è¡Œæ¥å£è§„èŒƒ**ï¼š
```python
#!/usr/bin/env python3
"""
åŠŸèƒ½æè¿°ï¼šèŒƒç•´è¯†åˆ«è„šæœ¬

ä½¿ç”¨æ–¹å¼ï¼š
  python identify_categories.py --input codes.json --output categories.json
  
ä¾èµ–ï¼š
  - pandas>=2.0.0
  - scikit-learn>=1.3.0
"""
import argparse
import json
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description='è¯†åˆ«èŒƒç•´')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥çš„ç¼–ç JSONæ–‡ä»¶')
    parser.add_argument('--output', '-o', default='categories.json', help='è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--min-codes', type=int, default=3, help='æ¯ä¸ªèŒƒç•´æœ€å°‘ç¼–ç æ•°')
    args = parser.parse_args()
    
    # å¤„ç†é€»è¾‘
    result = process_categories(args.input, args.min_codes)
    
    # æ ‡å‡†åŒ–è¾“å‡º
    output = {
        'summary': {
            'total_categories': len(result['categories']),
            'processing_time': result['time']
        },
        'details': {
            'categories': result['categories'],
            'statistics': result['stats']
        },
        'metadata': {
            'input_file': args.input,
            'timestamp': datetime.now().isoformat(),
            'version': '1.0.0'
        }
    }
    
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… è¯†åˆ«å®Œæˆï¼š{len(result['categories'])}ä¸ªèŒƒç•´")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœï¼š{args.output}")

if __name__ == '__main__':
    main()
```

**è¾“å‡ºæ ¼å¼æ ‡å‡†**ï¼š
```json
{
  "summary": {
    "total_items": 100,
    "success_rate": 0.95,
    "processing_time": 2.5
  },
  "details": {
    "items": [...],
    "statistics": {...}
  },
  "metadata": {
    "input_file": "data.txt",
    "timestamp": "2025-12-18T10:30:00",
    "version": "1.0.0"
  }
}
```

---

### 4. ä¸­æ–‡æ–‡æœ¬å¤„ç†ä¼˜åŒ–

**jieba + uvé›†æˆï¼ˆpyproject.tomlï¼‰**ï¼š
```toml
[project]
name = "performing-axial-coding"
version = "1.0.0"
requires-python = ">=3.8"
dependencies = [
    "jieba>=0.42.1",
    "pandas>=2.0.0",
    "scikit-learn>=1.3.0",
]

[tool.uv]
# ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿ
[[tool.uv.index]]
name = "tsinghua"
url = "https://pypi.tuna.tsinghua.edu.cn/simple/"
default = true

# ç¼“å­˜jiebaè¯å…¸
[tool.uv.cache]
keys = ["jieba"]
```

**ä¸­æ–‡åˆ†è¯ä¼˜åŒ–**ï¼š
```python
import jieba
import jieba.posseg as pseg

# é¢„åŠ è½½å­¦æœ¯è¯å…¸
jieba.load_userdict("academic_terms.txt")

# åœç”¨è¯è¿‡æ»¤
stopwords = set(line.strip() for line in open('stopwords.txt', 'r', encoding='utf-8'))

def tokenize_chinese(text):
    """ä¸­æ–‡åˆ†è¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    words = pseg.cut(text)
    return [w.word for w in words 
            if w.word not in stopwords 
            and len(w.word) > 1
            and w.flag in ['n', 'v', 'a']]  # åªä¿ç•™åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯
```

---

### 5. SKILL.mdå†™ä½œæ¨¡å¼

**æ ‡å‡†æ¨¡æ¿**ï¼š
```markdown
---
name: skill-name
description: ä¸€å¥è¯æè¿°ä½•æ—¶ä½¿ç”¨æ­¤æŠ€èƒ½ï¼ˆç¬¬ä¸‰äººç§°ï¼Œ1-2å¥è¯ï¼‰
---

# æŠ€èƒ½ä¸­æ–‡åç§° (English Name)

ä¸€æ®µè¯æ€»ç»“æŠ€èƒ½çš„æ ¸å¿ƒåŠŸèƒ½å’Œä»·å€¼ã€‚

## ä½¿ç”¨æ—¶æœº

å½“ç”¨æˆ·æåˆ°ä»¥ä¸‹éœ€æ±‚æ—¶ï¼Œä½¿ç”¨æ­¤æŠ€èƒ½ï¼š
- "å…³é”®è¯1" æˆ– "åŒä¹‰è¯1"
- "å…³é”®è¯2" æˆ– "åŒä¹‰è¯2"
- "å…³é”®è¯3" æˆ– "åŒä¹‰è¯3"
- éœ€è¦æ‰§è¡ŒXXXä»»åŠ¡

## å¿«é€Ÿå·¥å…·

```bash
# æ ¸å¿ƒè„šæœ¬è°ƒç”¨ï¼ˆä¸€è¡Œå‘½ä»¤ï¼‰
python scripts/main_script.py --input data.txt --output result.json
```

## æ‰§è¡Œæ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šä»»åŠ¡å‡†å¤‡
1. **å­æ­¥éª¤1**
   - å…·ä½“æ“ä½œè¯´æ˜
   - æ³¨æ„äº‹é¡¹

2. **å­æ­¥éª¤2**
   - å…·ä½“æ“ä½œè¯´æ˜

### ç¬¬äºŒæ­¥ï¼šæ ¸å¿ƒå¤„ç†
ä½¿ç”¨è„šæœ¬æ‰§è¡Œç¡®å®šæ€§è®¡ç®—ï¼š
```bash
python scripts/calculator.py --input prepared.json
```

### ç¬¬ä¸‰æ­¥ï¼šç»“æœåˆ†æ
1. **åˆ†æè¾“å‡º**
   - è§£é‡Šå…³é”®æŒ‡æ ‡
   - è¯†åˆ«é‡è¦æ¨¡å¼

2. **è´¨é‡æ£€æŸ¥**
   - éªŒè¯ç»“æœåˆç†æ€§
   - æ£€æŸ¥å¼‚å¸¸å€¼

### ç¬¬å››æ­¥ï¼šè¾“å‡ºäº¤ä»˜
ç”Ÿæˆæ ‡å‡†åŒ–æŠ¥å‘Šã€‚

## è¾“å‡ºè¦æ±‚

### åŸºæœ¬è¾“å‡º
- æ ¸å¿ƒç»“æœï¼ˆ3-5é¡¹ï¼‰
- å…³é”®æŒ‡æ ‡ï¼ˆé‡åŒ–æ•°æ®ï¼‰

### é«˜çº§åˆ†æ
- æ·±å…¥è§£é‡Š
- ç†è®ºæ„ä¹‰

## è´¨é‡æ£€æŸ¥æ¸…å•

åœ¨å®Œæˆä»»åŠ¡åï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š

### æ•°æ®è´¨é‡
- [ ] è¾“å…¥æ•°æ®å®Œæ•´
- [ ] æ•°æ®æ ¼å¼æ­£ç¡®
- [ ] å¼‚å¸¸å€¼å¤„ç†

### ç»“æœè´¨é‡
- [ ] ç»“æœç¬¦åˆé¢„æœŸ
- [ ] æŒ‡æ ‡è®¡ç®—æ­£ç¡®
- [ ] è§£é‡Šåˆç†

### ä¸­æ–‡è¯­å¢ƒ
- [ ] æœ¯è¯­ä½¿ç”¨å‡†ç¡®
- [ ] æ–‡åŒ–é€‚é…æ°å½“

## å¸¸è§é—®é¢˜å¤„ç†

**é—®é¢˜1ï¼šXXX**
- è§£å†³ï¼šYYY
- æ–¹æ³•ï¼šZZZ

**é—®é¢˜2ï¼šXXX**
- è§£å†³ï¼šYYY

## æŠ€æœ¯è¯´æ˜

è¯¦ç»†çš„æŠ€æœ¯èƒŒæ™¯å’Œç†è®ºï¼Œå‚è§ï¼š
- `references/theory.md` - ç†è®ºèƒŒæ™¯
- `references/examples.md` - å®Œæ•´æ¡ˆä¾‹
- `scripts/README.md` - è„šæœ¬ä½¿ç”¨æŒ‡å—

## å®Œæˆæ ‡å¿—

å®Œæˆé«˜è´¨é‡çš„XXXåº”è¯¥äº§å‡ºï¼š
1. æ ‡å‡†åŒ–çš„JSONè¾“å‡º
2. è¯¦ç»†çš„åˆ†ææŠ¥å‘Š
3. å¯è§†åŒ–å›¾è¡¨ï¼ˆå¦‚é€‚ç”¨ï¼‰

---

*æ­¤æŠ€èƒ½ä¸ºXXXç ”ç©¶æä¾›å®Œæ•´æ”¯æŒã€‚*
```

---

### 6. JavaScriptæŠ€èƒ½çš„SOLIDæ¶æ„

**é€‚ç”¨åœºæ™¯**ï¼šç†è®ºåˆ†æç±»æŠ€èƒ½ï¼ˆANTã€åœºåŸŸåˆ†æï¼‰

**ç›®å½•ç»“æ„**ï¼š
```
skill-name/
â”œâ”€â”€ index.js              # ä¸»å…¥å£ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Analyzer.js       # æ ¸å¿ƒåˆ†æå™¨ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚   â”œâ”€â”€ Extractor.js      # æ•°æ®æå–å™¨ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚   â”œâ”€â”€ Validator.js      # éªŒè¯å™¨ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚   â””â”€â”€ interfaces/
â”‚       â”œâ”€â”€ IAnalyzer.js  # åˆ†æå™¨æ¥å£
â”‚       â””â”€â”€ IExtractor.js # æå–å™¨æ¥å£
â”œâ”€â”€ __tests__/
â”‚   â”œâ”€â”€ Analyzer.test.js
â”‚   â””â”€â”€ integration.test.js
â””â”€â”€ SKILL.md
```

**ä¾èµ–æ³¨å…¥ç¤ºä¾‹**ï¼š
```javascript
// index.js
class ParticipantSkill {
    constructor(extractor, analyzer, validator) {
        this.extractor = extractor;
        this.analyzer = analyzer;
        this.validator = validator;
    }
    
    async execute(inputData) {
        // 1. éªŒè¯è¾“å…¥
        const validationResult = this.validator.validate(inputData);
        if (!validationResult.isValid) {
            throw new Error(validationResult.errors.join(', '));
        }
        
        // 2. æå–æ•°æ®
        const extracted = await this.extractor.extract(inputData);
        
        // 3. åˆ†æå¤„ç†
        const analyzed = await this.analyzer.analyze(extracted);
        
        // 4. åˆ†å±‚è¾“å‡º
        return {
            overview: this._buildOverview(analyzed),
            summary: this._buildSummary(analyzed),
            details: analyzed
        };
    }
    
    _buildOverview(data) {
        return {
            title: "å‚ä¸è€…åˆ†ææ¦‚è§ˆ",
            keyFindings: data.topParticipants.slice(0, 3),
            description: `è¯†åˆ«äº†${data.totalParticipants}ä¸ªå‚ä¸è€…`
        };
    }
}

// ä½¿ç”¨
const skill = new ParticipantSkill(
    new TextExtractor(),
    new ParticipantAnalyzer(),
    new InputValidator()
);

const result = await skill.execute(inputText);
```

---

### 7. åˆ†å±‚è¾“å‡ºè®¾è®¡

**ä¸‰å±‚è¾“å‡ºç»“æ„**ï¼š
```javascript
{
  // ç¬¬1å±‚ï¼šæ ¸å¿ƒæ¦‚å¿µï¼ˆ5-10ç§’ç†è§£ï¼‰
  "overview": {
    "title": "è½´å¿ƒç¼–ç åˆ†æç»“æœ",
    "keyFindings": [
      "è¯†åˆ«äº†8ä¸ªä¸»è¦èŒƒç•´",
      "å»ºç«‹äº†12æ¡èŒƒç•´å…³ç³»",
      "æ ¸å¿ƒèŒƒç•´ä¸º'å­¦ä¹ æ”¯æŒ'"
    ],
    "description": "å®Œæˆäº†ä»25ä¸ªå¼€æ”¾ç¼–ç åˆ°8ä¸ªèŒƒç•´çš„æ•´åˆ"
  },
  
  // ç¬¬2å±‚ï¼šå…³é”®å‘ç°ï¼ˆ30ç§’é˜…è¯»ï¼‰
  "summary": {
    "metrics": {
      "totalCategories": 8,
      "totalRelationships": 12,
      "averageCodesPerCategory": 3.1
    },
    "topCategories": [
      {"name": "å­¦ä¹ æ”¯æŒ", "importance": 0.35},
      {"name": "æƒ…æ„Ÿè°ƒèŠ‚", "importance": 0.28},
      {"name": "ç›®æ ‡è®¾å®š", "importance": 0.22}
    ],
    "visualizations": [
      "category_network.png",
      "paradigm_model.png"
    ]
  },
  
  // ç¬¬3å±‚ï¼šè¯¦ç»†æ•°æ®ï¼ˆæ·±å…¥åˆ†æï¼‰
  "details": {
    "categories": [...],  // å®Œæ•´èŒƒç•´åˆ—è¡¨
    "relationships": [...],  // å®Œæ•´å…³ç³»åˆ—è¡¨
    "paradigm": {...},  // Paradigmæ¨¡å‹
    "rawData": {...}  // åŸå§‹æ•°æ®
  },
  
  // å…ƒæ•°æ®
  "metadata": {
    "skillName": "performing-axial-coding",
    "version": "1.0.0",
    "timestamp": "2025-12-18T10:30:00",
    "processingTime": 2.5,
    "inputFile": "codes.json"
  }
}
```

---

### 8. è´¨é‡ä¿è¯æœºåˆ¶

**æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰**ï¼š
```python
# tests/test_category_identifier.py
import pytest
from scripts.identify_categories import CategoryIdentifier

def test_identify_categories_from_codes():
    """æµ‹è¯•ä»ç¼–ç ä¸­è¯†åˆ«èŒƒç•´"""
    # Arrange
    codes = [
        {"code": "å¯»æ±‚å¸®åŠ©", "frequency": 10},
        {"code": "è·å¾—æ”¯æŒ", "frequency": 8},
        {"code": "å»ºç«‹å…³ç³»", "frequency": 5}
    ]
    identifier = CategoryIdentifier(min_codes=2)
    
    # Act
    categories = identifier.identify(codes)
    
    # Assert
    assert len(categories) >= 1
    assert categories[0]['name'] in ['å­¦ä¹ æ”¯æŒ', 'ç¤¾äº¤æ”¯æŒ']
    assert all(len(c['codes']) >= 2 for c in categories)

def test_handle_insufficient_codes():
    """æµ‹è¯•å¤„ç†ç¼–ç ä¸è¶³çš„æƒ…å†µ"""
    codes = [{"code": "å•ä¸ªç¼–ç ", "frequency": 1}]
    identifier = CategoryIdentifier(min_codes=3)
    
    with pytest.raises(ValueError, match="è‡³å°‘éœ€è¦3ä¸ªç¼–ç "):
        identifier.identify(codes)
```

**è´¨é‡æ£€æŸ¥æ¸…å•**ï¼š
```markdown
## SKILL.mdè´¨é‡æ ‡å‡†
- [ ] YAML frontmatterå®Œæ•´ï¼ˆname + descriptionï¼‰
- [ ] descriptionæ˜¯ç¬¬ä¸‰äººç§°ï¼Œ1-2å¥è¯
- [ ] è§¦å‘æ¡ä»¶æ¸…æ™°ï¼ˆè‡³å°‘6ä¸ªå…³é”®è¯ï¼‰
- [ ] æ‰§è¡Œæ­¥éª¤å¯æ“ä½œï¼ˆ4æ­¥æ³•ï¼‰
- [ ] æœ‰è´¨é‡æ£€æŸ¥æ¸…å•
- [ ] æœ‰å¸¸è§é—®é¢˜å¤„ç†
- [ ] å¼•ç”¨äº†scripts/å’Œreferences/
- [ ] ä¸­æ–‡è¯­å¢ƒé€‚é…è‰¯å¥½
- [ ] æ–‡æ¡£é•¿åº¦â‰¤5000å­—

## è„šæœ¬è´¨é‡æ ‡å‡†
- [ ] æ ‡å‡†å‘½ä»¤è¡Œæ¥å£ï¼ˆargparseï¼‰
- [ ] JSONæ ‡å‡†åŒ–è¾“å‡ºï¼ˆsummary + details + metadataï¼‰
- [ ] é”™è¯¯å¤„ç†å®Œå–„ï¼ˆtry-except + å‹å¥½æç¤ºï¼‰
- [ ] æ€§èƒ½æŒ‡æ ‡è®°å½•ï¼ˆprocessing_timeï¼‰
- [ ] æœ‰å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡â‰¥80%ï¼‰
- [ ] æœ‰ä½¿ç”¨æ–‡æ¡£ï¼ˆdocstring + READMEï¼‰
- [ ] ä¾èµ–ç®¡ç†æ¸…æ™°ï¼ˆpyproject.tomlæˆ–package.jsonï¼‰
```

---

### 9. æŠ€èƒ½å¼€å‘å®Œæ•´æµç¨‹

**é˜¶æ®µ1ï¼šéœ€æ±‚åˆ†æï¼ˆ1å¤©ï¼‰**
1. è¯†åˆ«æŠ€èƒ½çš„æ ¸å¿ƒåŠŸèƒ½
2. ç¡®å®šè§¦å‘æ¡ä»¶ï¼ˆå…³é”®è¯ï¼‰
3. åˆ†æå®šæ€§vså®šé‡éƒ¨åˆ†
4. è®¾è®¡è¾“å…¥è¾“å‡ºæ ¼å¼

**é˜¶æ®µ2ï¼šæ¶æ„è®¾è®¡ï¼ˆ1å¤©ï¼‰**
1. é€‰æ‹©å®ç°è¯­è¨€ï¼ˆPython/JavaScriptï¼‰
2. è®¾è®¡åˆ†å±‚ç»“æ„ï¼ˆSKILL.md + scripts/ + references/ï¼‰
3. è§„åˆ’è„šæœ¬æ¥å£ï¼ˆå‘½ä»¤è¡Œå‚æ•°ã€è¾“å‡ºæ ¼å¼ï¼‰
4. ç¡®å®šä¾èµ–åº“ï¼ˆjiebaã€NetworkXã€scikit-learnç­‰ï¼‰

**é˜¶æ®µ3ï¼šå®ç°å¼€å‘ï¼ˆ3-5å¤©ï¼‰**
1. ç¼–å†™SKILL.mdï¼ˆç¬¬1å±‚æç¤ºè¯ï¼‰
   - YAML frontmatter
   - ä½¿ç”¨æ—¶æœº
   - å¿«é€Ÿå·¥å…·
   - æ‰§è¡Œæ­¥éª¤
   - è´¨é‡æ£€æŸ¥æ¸…å•

2. å®ç°scripts/ï¼ˆç¬¬3å±‚è„šæœ¬ï¼‰
   - æ ¸å¿ƒè®¡ç®—è„šæœ¬
   - å¯è§†åŒ–è„šæœ¬
   - éªŒè¯è„šæœ¬

3. åˆ›å»ºreferences/ï¼ˆç¬¬2å±‚ä¸Šä¸‹æ–‡ï¼‰
   - ç†è®ºèƒŒæ™¯ï¼ˆtheory.mdï¼‰
   - å®Œæ•´æ¡ˆä¾‹ï¼ˆexamples.mdï¼‰
   - æ•…éšœæ’é™¤ï¼ˆtroubleshooting.mdï¼‰

**é˜¶æ®µ4ï¼šæµ‹è¯•éªŒè¯ï¼ˆ2å¤©ï¼‰**
1. å•å…ƒæµ‹è¯•ï¼ˆ__tests__/æˆ–tests/unit/ï¼‰
2. é›†æˆæµ‹è¯•ï¼ˆtests/integration/ï¼‰
3. ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆçœŸå®æ•°æ®ï¼‰
4. æ€§èƒ½æµ‹è¯•ï¼ˆå¤§è§„æ¨¡æ•°æ®ï¼‰

**é˜¶æ®µ5ï¼šæ–‡æ¡£å®Œå–„ï¼ˆ1å¤©ï¼‰**
1. è¡¥å……ä½¿ç”¨ç¤ºä¾‹
2. æ·»åŠ æ•…éšœæ’é™¤æŒ‡å—
3. æ›´æ–°SKILLS_MANIFEST.md
4. ç¼–å†™README.mdï¼ˆå¦‚ç‹¬ç«‹æŠ€èƒ½ï¼‰

**é˜¶æ®µ6ï¼šè´¨é‡å®¡è®¡ï¼ˆ1å¤©ï¼‰**
1. è¿è¡Œvalidate_skills.py
2. æ£€æŸ¥è´¨é‡æ£€æŸ¥æ¸…å•
3. ä»£ç å®¡æŸ¥
4. æ–‡æ¡£å®¡æŸ¥

---

### 10. ä¸­æ–‡æœ¬åœŸåŒ–é€‚é…

**æœ¯è¯­æœ¬åœŸåŒ–**ï¼š
```python
# ä¸­æ–‡ç¤¾ç§‘æœ¯è¯­æ˜ å°„
CHINESE_TERMS = {
    'guanxi_capital': 'å…³ç³»èµ„æœ¬',
    'danwei_system': 'å•ä½åˆ¶åº¦',
    'political_capital': 'æ”¿æ²»èµ„æœ¬',
    'face_concept': 'é¢å­è§‚å¿µ',
    'hierarchy_acceptance': 'ç­‰çº§æ¥å—åº¦'
}

# åœºåŸŸåˆ†æçš„ä¸­å›½ç‰¹è‰²
class ChineseFieldAdapter:
    def adapt_field_features(self, field_data):
        """è¯†åˆ«ä¸­å›½ç‰¹è‰²çš„åœºåŸŸç‰¹å¾"""
        features = {
            'danwei_influence': self._calculate_danwei_influence(field_data),
            'guanxi_importance': self._calculate_guanxi_importance(field_data),
            'political_capital_role': self._calculate_political_capital(field_data)
        }
        return features
```

**æ–‡åŒ–æ•æ„Ÿæ€§å¤„ç†**ï¼š
```markdown
## ä¸­æ–‡è¯­å¢ƒé€‚é…

### å…³ç³»èµ„æœ¬ï¼ˆGuanxi Capitalï¼‰
åœ¨ä¸­å›½ç¤¾ä¼šä¸­ï¼Œ"å…³ç³»"ä¸ä»…æ˜¯ç¤¾ä¼šèµ„æœ¬ï¼Œæ›´æ˜¯ä¸€ç§ç‹¬ç‰¹çš„æ–‡åŒ–ç°è±¡ï¼š
- å·®åºæ ¼å±€ï¼šå…³ç³»çš„äº²ç–è¿œè¿‘
- äººæƒ…å¾€æ¥ï¼šäº’æƒ æ€§åŸåˆ™
- é¢å­ç»´æŠ¤ï¼šç¤¾ä¼šå£°èª‰ç®¡ç†

### å•ä½åˆ¶åº¦ï¼ˆDanwei Systemï¼‰
è™½ç„¶å•ä½åˆ¶åº¦å·²ç»å¼±åŒ–ï¼Œä½†ä»ç„¶å½±å“ç€ï¼š
- èµ„æºåˆ†é…æ–¹å¼
- ç¤¾ä¼šèº«ä»½è®¤åŒ
- èŒä¸šå‘å±•è·¯å¾„
```

---

## å®è·µæŒ‡å—

### æŒ‡å—1ï¼šä½•æ—¶ä½¿ç”¨Python vs JavaScript

**ä½¿ç”¨Pythonçš„åœºæ™¯**ï¼š
- âœ… ä¸­æ–‡æ–‡æœ¬å¤„ç†ï¼ˆjiebaåˆ†è¯ï¼‰
- âœ… æ•°æ®åˆ†æï¼ˆpandasã€numpyï¼‰
- âœ… æœºå™¨å­¦ä¹ ï¼ˆscikit-learnï¼‰
- âœ… ç»Ÿè®¡åˆ†æï¼ˆscipy.statsï¼‰
- âœ… ç½‘ç»œåˆ†æï¼ˆNetworkXï¼‰

**ä½¿ç”¨JavaScriptçš„åœºæ™¯**ï¼š
- âœ… ç†è®ºåˆ†æï¼ˆANTã€åœºåŸŸåˆ†æï¼‰
- âœ… éœ€è¦SOLIDæ¶æ„
- âœ… å¤æ‚çš„ä¾èµ–æ³¨å…¥
- âœ… å‰ç«¯å¯è§†åŒ–ï¼ˆD3.jsï¼‰

---

### æŒ‡å—2ï¼šè„šæœ¬å¼€å‘æœ€ä½³å®è·µ

**ä½¿ç”¨uvåŒ…ç®¡ç†ï¼ˆæ¨èï¼‰**ï¼š
```toml
# pyproject.toml
[project]
name = "skill-name"
version = "1.0.0"
requires-python = ">=3.8"
dependencies = [
    "jieba>=0.42.1",
    "pandas>=2.0.0",
]

[tool.uv]
[[tool.uv.index]]
name = "tsinghua"
url = "https://pypi.tuna.tsinghua.edu.cn/simple/"
default = true
```

**æ ‡å‡†åŒ–é”™è¯¯å¤„ç†**ï¼š
```python
import sys
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def main():
    try:
        # å¤„ç†é€»è¾‘
        result = process_data(args.input)
        
    except FileNotFoundError as e:
        logging.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        sys.exit(1)
        
    except ValueError as e:
        logging.error(f"æ•°æ®æ ¼å¼é”™è¯¯: {e}")
        sys.exit(2)
        
    except Exception as e:
        logging.error(f"æœªçŸ¥é”™è¯¯: {e}")
        sys.exit(99)
    
    logging.info(f"âœ… å¤„ç†å®Œæˆ")
```

---

### æŒ‡å—3ï¼šSKILL.mdä¼˜åŒ–æŠ€å·§

**ä¿æŒç®€æ´ï¼ˆâ‰¤5000å­—ï¼‰**ï¼š
```markdown
## æ‰§è¡Œæ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šæ•°æ®å‡†å¤‡
ä½¿ç”¨è„šæœ¬é¢„å¤„ç†æ•°æ®ï¼š
```bash
python scripts/preprocess.py --input raw.txt --output clean.json
```

è¯¦ç»†çš„é¢„å¤„ç†è¯´æ˜ï¼Œå‚è§ `references/preprocessing-guide.md`
```

**é¿å…è¿‡åº¦è¯¦ç»†**ï¼š
```markdown
âŒ ä¸å¥½çš„å†™æ³•ï¼ˆè¿‡äºè¯¦ç»†ï¼‰ï¼š
## ä¸­å¿ƒæ€§åˆ†æåŸç†
åº¦ä¸­å¿ƒæ€§çš„è®¡ç®—å…¬å¼ä¸ºï¼šC_D(v) = deg(v) / (n-1)
å…¶ä¸­deg(v)æ˜¯èŠ‚ç‚¹vçš„åº¦æ•°ï¼Œnæ˜¯ç½‘ç»œèŠ‚ç‚¹æ€»æ•°...
ï¼ˆç»§ç»­500å­—çš„æ•°å­¦æ¨å¯¼ï¼‰

âœ… å¥½çš„å†™æ³•ï¼ˆç®€æ´+å¼•ç”¨ï¼‰ï¼š
## ä¸­å¿ƒæ€§åˆ†æ
ä½¿ç”¨è„šæœ¬è®¡ç®—å››ç§ä¸­å¿ƒæ€§æŒ‡æ ‡ï¼š
```bash
python scripts/centrality.py --input network.json
```

è¯¦ç»†çš„ç†è®ºèƒŒæ™¯å’Œå…¬å¼æ¨å¯¼ï¼Œå‚è§ `references/centrality-theory.md`
```

---

### æŒ‡å—4ï¼šæµ‹è¯•ç­–ç•¥

**å•å…ƒæµ‹è¯•ï¼ˆ80%è¦†ç›–ç‡ï¼‰**ï¼š
```python
# tests/test_extractor.py
def test_extract_concepts():
    extractor = ConceptExtractor()
    text = "å­¦ç”Ÿå¯»æ±‚è€å¸ˆçš„å¸®åŠ©"
    concepts = extractor.extract(text)
    assert "å¯»æ±‚å¸®åŠ©" in concepts

def test_handle_empty_text():
    extractor = ConceptExtractor()
    with pytest.raises(ValueError):
        extractor.extract("")
```

**é›†æˆæµ‹è¯•**ï¼š
```python
# tests/integration/test_workflow.py
def test_complete_workflow():
    # 1. é¢„å¤„ç†
    preprocess_result = subprocess.run(
        ['python', 'scripts/preprocess.py', '--input', 'test_data/raw.txt'],
        capture_output=True
    )
    assert preprocess_result.returncode == 0
    
    # 2. æ¦‚å¿µæå–
    extract_result = subprocess.run(
        ['python', 'scripts/extract.py', '--input', 'clean.json'],
        capture_output=True
    )
    assert extract_result.returncode == 0
    
    # 3. éªŒè¯è¾“å‡º
    with open('concepts.json') as f:
        data = json.load(f)
    assert 'summary' in data
    assert 'details' in data
```

---

## åæ¨¡å¼è­¦ç¤º

### åæ¨¡å¼1ï¼šSKILL.mdè¿‡äºè¯¦ç»†
```markdown
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
## èšç±»ç®—æ³•è¯¦è§£
K-meansç®—æ³•çš„æ­¥éª¤å¦‚ä¸‹ï¼š
1. éšæœºé€‰æ‹©kä¸ªåˆå§‹ä¸­å¿ƒç‚¹
2. è®¡ç®—æ¯ä¸ªæ•°æ®ç‚¹åˆ°ä¸­å¿ƒç‚¹çš„è·ç¦»
3. å°†æ•°æ®ç‚¹åˆ†é…åˆ°æœ€è¿‘çš„ä¸­å¿ƒç‚¹
4. é‡æ–°è®¡ç®—æ¯ä¸ªç°‡çš„ä¸­å¿ƒç‚¹
5. é‡å¤æ­¥éª¤2-4ç›´åˆ°æ”¶æ•›
ï¼ˆç»§ç»­1000å­—çš„ç®—æ³•è¯¦è§£å’Œä»£ç ç¤ºä¾‹ï¼‰

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
## èŒƒç•´è¯†åˆ«
ä½¿ç”¨èšç±»ç®—æ³•è‡ªåŠ¨è¯†åˆ«èŒƒç•´ï¼š
```bash
python scripts/identify_categories.py --input codes.json
```

ç®—æ³•ç»†èŠ‚å‚è§ `references/clustering-algorithm.md`
```

---

### åæ¨¡å¼2ï¼šç¼ºå°‘è„šæœ¬æ”¯æŒ
```markdown
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
## ä¸­å¿ƒæ€§è®¡ç®—
è¯·æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„åº¦ä¸­å¿ƒæ€§ï¼š
1. ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ•°
2. é™¤ä»¥(n-1)å¾—åˆ°æ ‡å‡†åŒ–åº¦ä¸­å¿ƒæ€§
3. é‡å¤ä»¥ä¸Šæ­¥éª¤è®¡ç®—å…¶ä»–ä¸­å¿ƒæ€§...

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
## ä¸­å¿ƒæ€§è®¡ç®—
```bash
python scripts/centrality.py --input network.json --output centrality.json
```
è„šæœ¬è‡ªåŠ¨è®¡ç®—å››ç§ä¸­å¿ƒæ€§æŒ‡æ ‡ã€‚
```

---

### åæ¨¡å¼3ï¼šè¾“å‡ºæ ¼å¼ä¸ä¸€è‡´
```markdown
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
# è„šæœ¬Aè¾“å‡º
{"result": [...]}

# è„šæœ¬Bè¾“å‡º
{"data": {...}, "status": "ok"}

# è„šæœ¬Cè¾“å‡º
[1, 2, 3, 4, 5]

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
# æ‰€æœ‰è„šæœ¬ç»Ÿä¸€è¾“å‡ºæ ¼å¼
{
  "summary": {...},
  "details": {...},
  "metadata": {...}
}
```

---

### åæ¨¡å¼4ï¼šå¿½è§†ä¸­æ–‡è¯­å¢ƒ
```markdown
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
è¯†åˆ«äº†ä»¥ä¸‹capital types:
- cultural_capital
- social_capital
- economic_capital

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
è¯†åˆ«äº†ä»¥ä¸‹èµ„æœ¬ç±»å‹ï¼š
- æ–‡åŒ–èµ„æœ¬ï¼ˆå­¦å†ã€çŸ¥è¯†ã€å“å‘³ï¼‰
- ç¤¾ä¼šèµ„æœ¬ï¼ˆå…³ç³»ç½‘ç»œã€ç¤¾ä¼šåœ°ä½ï¼‰
- ç»æµèµ„æœ¬ï¼ˆè´¢å¯Œã€æ”¶å…¥ï¼‰
- æ”¿æ²»èµ„æœ¬ï¼ˆæƒåŠ›ã€èŒä½ï¼‰[ä¸­å›½æ‰©å±•]
- å…³ç³»èµ„æœ¬ï¼ˆäººè„‰ã€é¢å­ï¼‰[ä¸­å›½æ‰©å±•]
```

---

### åæ¨¡å¼5ï¼šæŠ€èƒ½é‡å¤
```markdown
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
skills/
â”œâ”€â”€ centrality-analysis/SKILL.md  # ç®€åŒ–ç‰ˆ
â””â”€â”€ performing-centrality-analysis/SKILL.md  # è¯¦ç»†ç‰ˆ

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
skills/
â””â”€â”€ performing-centrality-analysis/
    â”œâ”€â”€ SKILL.md  # ç»Ÿä¸€çš„è¯¦ç»†ç‰ˆ
    â”œâ”€â”€ scripts/
    â””â”€â”€ references/
```

---

### åæ¨¡å¼6ï¼šè¿‡åº¦è®¾è®¡ï¼ˆè¿åYAGNIï¼‰
```python
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
class CategoryIdentifier:
    def __init__(self, strategy_factory, config_manager, logger_factory, 
                 cache_manager, event_bus, metrics_collector):
        # è¿‡åº¦è®¾è®¡ï¼Œå¼•å…¥äº†ä¸å¿…è¦çš„å¤æ‚æ€§
        pass

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
class CategoryIdentifier:
    def __init__(self, min_codes=3):
        self.min_codes = min_codes
    
    def identify(self, codes):
        # ç®€å•ç›´æ¥ï¼Œæ»¡è¶³éœ€æ±‚å³å¯
        pass
```

---

### åæ¨¡å¼7ï¼šç¼ºå°‘æµ‹è¯•
```markdown
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
skill-name/
â”œâ”€â”€ SKILL.md
â””â”€â”€ scripts/
    â””â”€â”€ calculator.py  # æ²¡æœ‰æµ‹è¯•

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
skill-name/
â”œâ”€â”€ SKILL.md
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ calculator.py
â””â”€â”€ __tests__/
    â””â”€â”€ calculator.test.py  # æœ‰æµ‹è¯•
```

---

### åæ¨¡å¼8ï¼šç¡¬ç¼–ç é…ç½®
```python
âŒ é”™è¯¯ç¤ºä¾‹ï¼š
def identify_categories(codes):
    # ç¡¬ç¼–ç çš„é˜ˆå€¼
    if len(codes) < 3:
        raise ValueError("è‡³å°‘éœ€è¦3ä¸ªç¼–ç ")
    
    # ç¡¬ç¼–ç çš„èšç±»å‚æ•°
    kmeans = KMeans(n_clusters=5, random_state=42)

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
def identify_categories(codes, min_codes=3, n_clusters=None):
    if len(codes) < min_codes:
        raise ValueError(f"è‡³å°‘éœ€è¦{min_codes}ä¸ªç¼–ç ")
    
    # è‡ªåŠ¨ç¡®å®šèšç±»æ•°
    if n_clusters is None:
        n_clusters = estimate_optimal_clusters(codes)
    
    kmeans = KMeans(n_clusters=n_clusters)
```

---

## è´¨é‡æ£€æŸ¥æ€»æ¸…å•

### SKILL.mdè´¨é‡
- [ ] YAML frontmatterå®Œæ•´ï¼ˆname + descriptionï¼‰
- [ ] descriptionç¬¬ä¸‰äººç§°ï¼Œ1-2å¥è¯
- [ ] è§¦å‘æ¡ä»¶æ¸…æ™°ï¼ˆâ‰¥6ä¸ªå…³é”®è¯ï¼‰
- [ ] æ‰§è¡Œæ­¥éª¤å¯æ“ä½œï¼ˆ4æ­¥æ³•ï¼‰
- [ ] æœ‰å¿«é€Ÿå·¥å…·è°ƒç”¨ç¤ºä¾‹
- [ ] æœ‰è´¨é‡æ£€æŸ¥æ¸…å•
- [ ] æœ‰å¸¸è§é—®é¢˜å¤„ç†
- [ ] å¼•ç”¨äº†scripts/å’Œreferences/
- [ ] ä¸­æ–‡è¯­å¢ƒé€‚é…è‰¯å¥½
- [ ] æ–‡æ¡£é•¿åº¦â‰¤5000å­—

### è„šæœ¬è´¨é‡
- [ ] æ ‡å‡†å‘½ä»¤è¡Œæ¥å£ï¼ˆargparseï¼‰
- [ ] JSONæ ‡å‡†åŒ–è¾“å‡ºï¼ˆsummary + details + metadataï¼‰
- [ ] é”™è¯¯å¤„ç†å®Œå–„ï¼ˆtry-except + å‹å¥½æç¤ºï¼‰
- [ ] æ€§èƒ½æŒ‡æ ‡è®°å½•ï¼ˆprocessing_timeï¼‰
- [ ] æœ‰å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡â‰¥80%ï¼‰
- [ ] æœ‰ä½¿ç”¨æ–‡æ¡£ï¼ˆdocstring + READMEï¼‰
- [ ] ä¾èµ–ç®¡ç†æ¸…æ™°ï¼ˆpyproject.tomlï¼‰
- [ ] ä½¿ç”¨uvåŒ…ç®¡ç†ï¼ˆæ¨èï¼‰

### æ¶æ„è´¨é‡
- [ ] å®šæ€§å®šé‡ä¸¥æ ¼åˆ†ç¦»
- [ ] ä¸‰å±‚ä¿¡æ¯æŠ«éœ²å®Œæ•´
- [ ] åˆ†å±‚è¾“å‡ºæ ¼å¼ç»Ÿä¸€
- [ ] ç›®å½•ç»“æ„è§„èŒƒ
- [ ] æ— é‡å¤æ–‡ä»¶

### æµ‹è¯•è´¨é‡
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡â‰¥80%
- [ ] æœ‰é›†æˆæµ‹è¯•
- [ ] æœ‰ç«¯åˆ°ç«¯æµ‹è¯•
- [ ] æµ‹è¯•æ•°æ®å……åˆ†

### æ–‡æ¡£è´¨é‡
- [ ] æœ‰ç†è®ºèƒŒæ™¯ï¼ˆreferences/theory.mdï¼‰
- [ ] æœ‰å®Œæ•´æ¡ˆä¾‹ï¼ˆreferences/examples.mdï¼‰
- [ ] æœ‰æ•…éšœæ’é™¤ï¼ˆreferences/troubleshooting.mdï¼‰
- [ ] æœ‰è„šæœ¬ä½¿ç”¨æŒ‡å—ï¼ˆscripts/README.mdï¼‰

---

## é™„å½•ï¼šå‚è€ƒæ–‡ä»¶æ¸…å•

### æœ€ä½³å®è·µç¤ºä¾‹

**PythonæŠ€èƒ½ï¼ˆä¸­æ–‡æ–‡æœ¬å¤„ç†ï¼‰**ï¼š
- `skills/coding/open-coding/SKILL.md` - ç®€æ´çš„å·¥å…·å¯¼å‘è®¾è®¡
- `skills/coding/open-coding/scripts/extract_concepts.py` - æ ‡å‡†è„šæœ¬æ¥å£
- `skills/coding/open-coding/pyproject.toml` - uvåŒ…ç®¡ç†é…ç½®

**JavaScriptæŠ€èƒ½ï¼ˆç†è®ºåˆ†æï¼‰**ï¼š
- `skills/ant/participant-skill/index.js` - SOLIDæ¶æ„ä¸»å…¥å£
- `skills/ant/participant-skill/src/ParticipantExtractor.js` - å•ä¸€èŒè´£å®ç°

**æ¶æ„æ–‡æ¡£**ï¼š
- `SKILLS_ARCHITECTURE_AUDIT.md` - å®šæ€§å®šé‡åˆ†ç¦»åŸåˆ™
- `SKILLS_QUALITY_AUDIT.md` - è´¨é‡è¯„ä¼°æ ‡å‡†
- `SKILLS_OPTIMIZATION_GUIDE.md` - è®¾è®¡å“²å­¦

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æŠ€èƒ½ = æç¤ºè¯ + è„šæœ¬ + ä¸Šä¸‹æ–‡**
2. **å®šæ€§å®šé‡ä¸¥æ ¼åˆ†ç¦»**ï¼šæ™ºèƒ½åˆ†æç”¨æç¤ºè¯ï¼Œç¡®å®šæ€§è®¡ç®—ç”¨è„šæœ¬
3. **ä¸‰å±‚ä¿¡æ¯æŠ«éœ²**ï¼šä¼˜åŒ–AIä¸Šä¸‹æ–‡è´Ÿè½½
4. **æ ‡å‡†åŒ–æ¥å£**ï¼šç»Ÿä¸€çš„å‘½ä»¤è¡Œæ¥å£å’Œè¾“å‡ºæ ¼å¼
5. **ä¸­æ–‡æœ¬åœŸåŒ–**ï¼šjiebaä¼˜åŒ– + æ–‡åŒ–é€‚é…
6. **è´¨é‡ä¿è¯**ï¼šTDD + è´¨é‡æ£€æŸ¥æ¸…å•
7. **é¿å…åæ¨¡å¼**ï¼šè¿‡åº¦è¯¦ç»†ã€ç¼ºå°‘è„šæœ¬ã€è¾“å‡ºä¸ä¸€è‡´ã€å¿½è§†ä¸­æ–‡

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. ä½¿ç”¨æœ¬æ–¹æ³•è®ºå®¡æŸ¥ç°æœ‰æŠ€èƒ½
2. è¯†åˆ«ä¸ç¬¦åˆè§„èŒƒçš„æŠ€èƒ½
3. æŒ‰ä¼˜å…ˆçº§ä¿®å¤é—®é¢˜
4. å¼€å‘æ–°æŠ€èƒ½æ—¶ä¸¥æ ¼éµå¾ªæ–¹æ³•è®º
5. æŒç»­ä¼˜åŒ–å’Œè¿­ä»£

---

*æœ¬æ–¹æ³•è®ºåŸºäºsscisubagent-skillsæŠ€èƒ½åŒ…çš„æ·±åº¦åˆ†ææå–ï¼Œé€‚ç”¨äºæ‰€æœ‰Claude Skillsçš„å¼€å‘ã€‚*
