#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èŒƒç•´è¯†åˆ«è„šæœ¬ - è½´å¿ƒç¼–ç 

åŠŸèƒ½ï¼š
- ä»å¼€æ”¾ç¼–ç ç»“æœèšç±»ä¸ºèŒƒç•´
- èŒƒç•´å‘½åå’Œå®šä¹‰
- æ„å»ºèŒƒç•´å±‚çº§

ä½¿ç”¨æ–¹å¼ï¼š
  python identify_categories.py --input codes.json --output categories.json
"""

import argparse
import json
import logging
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict
from collections import Counter
import numpy as np
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.feature_extraction.text import TfidfVectorizer

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def cluster_codes_to_categories(codes: List[Dict], n_categories: int = None, min_codes: int = 3) -> List[Dict]:
    """
    å°†ç¼–ç èšç±»ä¸ºèŒƒç•´
    
    Args:
        codes: ç¼–ç åˆ—è¡¨
        n_categories: èŒƒç•´æ•°é‡ï¼ˆNoneåˆ™è‡ªåŠ¨ç¡®å®šï¼‰
        min_codes: æ¯ä¸ªèŒƒç•´æœ€å°‘ç¼–ç æ•°
    
    Returns:
        èŒƒç•´åˆ—è¡¨
    """
    if len(codes) < min_codes:
        raise ValueError(f"ç¼–ç æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦{min_codes}ä¸ªï¼‰")
    
    # è‡ªåŠ¨ç¡®å®šèŒƒç•´æ•°
    if n_categories is None:
        n_categories = max(2, min(len(codes) // 5, 15))
        logging.info(f"è‡ªåŠ¨ç¡®å®šèŒƒç•´æ•°: {n_categories}")
    
    # æå–ç¼–ç æ–‡æœ¬
    code_texts = [c.get('concept') or c.get('code', '') for c in codes]
    
    # ä½¿ç”¨TF-IDFå‘é‡åŒ–ï¼ˆç®€å•å®ç°ï¼Œä¸ä¾èµ–jiebaï¼‰
    vectorizer = TfidfVectorizer(max_features=100)
    try:
        tfidf_matrix = vectorizer.fit_transform(code_texts)
    except Exception as e:
        logging.error(f"å‘é‡åŒ–å¤±è´¥: {e}")
        raise
    
    # K-meansèšç±»
    kmeans = KMeans(n_clusters=n_categories, random_state=42, n_init=10)
    labels = kmeans.fit_predict(tfidf_matrix)
    
    # ç»„ç»‡èŒƒç•´
    category_groups = {}
    for i, label in enumerate(labels):
        label = int(label)
        if label not in category_groups:
            category_groups[label] = []
        category_groups[label].append(codes[i])
    
    # è¿‡æ»¤å°èŒƒç•´
    categories = []
    for cat_id, cat_codes in category_groups.items():
        if len(cat_codes) >= min_codes:
            category = {
                'category_id': cat_id,
                'codes': cat_codes,
                'size': len(cat_codes),
                'total_frequency': sum(c.get('frequency', 1) for c in cat_codes)
            }
            categories.append(category)
    
    return sorted(categories, key=lambda x: x['total_frequency'], reverse=True)

def name_category(codes: List[Dict]) -> str:
    """
    ä¸ºèŒƒç•´å‘½å
    
    ç­–ç•¥ï¼šä½¿ç”¨æœ€é«˜é¢‘ç¼–ç ä½œä¸ºèŒƒç•´å
    
    Returns:
        èŒƒç•´åç§°
    """
    if not codes:
        return "æœªå‘½åèŒƒç•´"
    
    # é€‰æ‹©é¢‘ç‡æœ€é«˜çš„ç¼–ç 
    top_code = max(codes, key=lambda c: c.get('frequency', 1))
    return top_code.get('concept') or top_code.get('code', 'æœªå‘½å')

def define_category(codes: List[Dict]) -> str:
    """
    å®šä¹‰èŒƒç•´
    
    ç­–ç•¥ï¼šç»¼åˆæ‰€æœ‰ç¼–ç çš„å®šä¹‰
    
    Returns:
        èŒƒç•´å®šä¹‰
    """
    if not codes:
        return ""
    
    # æå–æ‰€æœ‰ç¼–ç çš„å…³é”®è¯
    all_words = []
    for code in codes:
        concept = code.get('concept') or code.get('code', '')
        all_words.extend(concept.split())
    
    # ç»Ÿè®¡é«˜é¢‘è¯
    word_freq = Counter(all_words)
    top_words = [w for w, _ in word_freq.most_common(5)]
    
    # ç”Ÿæˆå®šä¹‰
    definition = f"æ¶‰åŠ{', '.join(top_words[:3])}ç­‰ç›¸å…³æ¦‚å¿µçš„èŒƒç•´"
    return definition

def build_category_hierarchy(categories: List[Dict]) -> Dict:
    """
    æ„å»ºèŒƒç•´å±‚çº§ç»“æ„
    
    ç­–ç•¥ï¼šåŸºäºåŒ…å«å…³ç³»å’Œé¢‘ç‡
    
    Returns:
        å±‚çº§ç»“æ„å­—å…¸
    """
    # ç®€å•å®ç°ï¼šæŒ‰é¢‘ç‡åˆ†ä¸ºæ ¸å¿ƒèŒƒç•´å’Œæ¬¡è¦èŒƒç•´
    total_freq = sum(c['total_frequency'] for c in categories)
    
    core_categories = []
    secondary_categories = []
    
    for category in categories:
        proportion = category['total_frequency'] / total_freq
        if proportion > 0.15:  # å æ¯”>15%ä¸ºæ ¸å¿ƒèŒƒç•´
            core_categories.append(category['category_id'])
        else:
            secondary_categories.append(category['category_id'])
    
    return {
        'core': core_categories,
        'secondary': secondary_categories,
        'hierarchy_type': 'frequency_based'
    }

def calculate_category_importance(categories: List[Dict]) -> List[Dict]:
    """
    è®¡ç®—èŒƒç•´é‡è¦æ€§
    
    Returns:
        æ·»åŠ äº†importanceå­—æ®µçš„èŒƒç•´åˆ—è¡¨
    """
    total_freq = sum(c['total_frequency'] for c in categories)
    
    for category in categories:
        category['importance'] = round(category['total_frequency'] / total_freq, 3)
    
    return categories

def main():
    parser = argparse.ArgumentParser(
        description='èŒƒç•´è¯†åˆ«å·¥å…· - è½´å¿ƒç¼–ç ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python identify_categories.py --input codes.json --output categories.json
  python identify_categories.py -i codes.json -o result.json --n-categories 8
        """
    )
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥çš„ç¼–ç JSONæ–‡ä»¶')
    parser.add_argument('--output', '-o', default='categories.json', help='è¾“å‡ºJSONæ–‡ä»¶')
    parser.add_argument('--n-categories', '-n', type=int, help='èŒƒç•´æ•°é‡ï¼ˆé»˜è®¤è‡ªåŠ¨ç¡®å®šï¼‰')
    parser.add_argument('--min-codes', type=int, default=3, help='æ¯ä¸ªèŒƒç•´æœ€å°‘ç¼–ç æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰')
    args = parser.parse_args()
    
    start_time = time.time()
    
    try:
        # è¯»å–ç¼–ç æ•°æ®
        input_path = Path(args.input)
        if not input_path.exists():
            logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
            sys.exit(1)
        
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–ç¼–ç åˆ—è¡¨
        if 'details' in data and 'concepts' in data['details']:
            codes = data['details']['concepts']
        elif isinstance(data, list):
            codes = data
        else:
            logging.error("æ— æ³•è¯†åˆ«çš„æ•°æ®æ ¼å¼")
            sys.exit(2)
        
        if len(codes) < args.min_codes:
            logging.error(f"ç¼–ç æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦{args.min_codes}ä¸ªï¼‰")
            sys.exit(3)
        
        logging.info(f"âœ“ è¯»å–ç¼–ç : {len(codes)} ä¸ª")
        
        # èšç±»ä¸ºèŒƒç•´
        categories = cluster_codes_to_categories(codes, args.n_categories, args.min_codes)
        
        # ä¸ºæ¯ä¸ªèŒƒç•´å‘½åå’Œå®šä¹‰
        for category in categories:
            category['name'] = name_category(category['codes'])
            category['definition'] = define_category(category['codes'])
        
        # è®¡ç®—é‡è¦æ€§
        categories = calculate_category_importance(categories)
        
        # æ„å»ºå±‚çº§
        hierarchy = build_category_hierarchy(categories)
        
        processing_time = time.time() - start_time
        
        # æ„å»ºè¾“å‡º
        output = {
            'summary': {
                'total_categories': len(categories),
                'total_codes': len(codes),
                'core_categories': len(hierarchy['core']),
                'top_categories': [c['name'] for c in categories[:5]],
                'processing_time': round(processing_time, 2)
            },
            'details': {
                'categories': categories,
                'hierarchy': hierarchy
            },
            'metadata': {
                'input_file': str(input_path.absolute()),
                'timestamp': datetime.now().isoformat(),
                'version': '1.0.0'
            }
        }
        
        # ä¿å­˜
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        logging.info(f"âœ… èŒƒç•´è¯†åˆ«å®Œæˆ")
        logging.info(f"   è¯†åˆ«èŒƒç•´: {len(categories)} ä¸ª")
        logging.info(f"   æ ¸å¿ƒèŒƒç•´: {len(hierarchy['core'])} ä¸ª")
        logging.info(f"   ä¸»è¦èŒƒç•´: {', '.join([c['name'] for c in categories[:3]])}")
        logging.info(f"ğŸ“„ è¯¦ç»†ç»“æœ: {args.output}")
        
    except Exception as e:
        logging.error(f"å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(99)

if __name__ == "__main__":
    main()
