#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è´¨é‡æå‡æµ‹è¯• - å¯¹æ¯”åŸå§‹ç‰ˆæœ¬å’Œä¼˜åŒ–ç‰ˆæœ¬çš„è´¨é‡å·®å¼‚
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'scripts'))

from optimized_weberian_analyzer import OptimizedWeberianAnalyzer


def test_quality_improvement():
    """æµ‹è¯•è´¨é‡æå‡æ•ˆæœ"""
    
    print("=== éŸ¦ä¼¯åˆ†æè´¨é‡æå‡æµ‹è¯• ===\n")
    
    # åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆåˆ†æå™¨
    analyzer = OptimizedWeberianAnalyzer()
    
    # æµ‹è¯•æ–‡æœ¬æ•°æ®
    test_text = """
    ç°ä»£å®˜åƒšç»„ç»‡ä½œä¸ºä¸€ç§ç†æ€§çš„ç»„ç»‡å½¢å¼ï¼Œè¿½æ±‚æ•ˆç‡æœ€å¤§åŒ–å’Œç¨‹åºè§„èŒƒåŒ–ã€‚
    ç»„ç»‡æˆå‘˜æŒ‰ç…§æ˜ç¡®çš„è§„åˆ™å’Œç¨‹åºè¡ŒåŠ¨ï¼Œä¸ªäººçš„æƒ…æ„Ÿå’Œåå¥½è¢«æ’é™¤åœ¨å†³ç­–è¿‡ç¨‹ä¹‹å¤–ã€‚
    è¿™ç§éäººæ ¼åŒ–çš„ç®¡ç†æ–¹å¼ç¡®ä¿äº†ç»„ç»‡çš„å…¬æ­£æ€§å’Œæ•ˆç‡ï¼Œä½“ç°äº†éŸ¦ä¼¯æ‰€è¯´çš„å½¢å¼ç†æ€§ã€‚
    
    ä»ç¤¾ä¼šè¡ŒåŠ¨çš„è§’åº¦çœ‹ï¼Œç»„ç»‡æˆå‘˜çš„è¡Œä¸ºä¸»è¦è¡¨ç°ä¸ºç›®çš„ç†æ€§è¡ŒåŠ¨ï¼Œ
    ä»–ä»¬ä¸ºäº†å®ç°ç»„ç»‡ç›®æ ‡è€Œé€‰æ‹©æœ€æœ‰æ•ˆçš„æ‰‹æ®µã€‚ç„¶è€Œï¼Œåœ¨ç»„ç»‡æ–‡åŒ–å±‚é¢ï¼Œ
    ä»·å€¼ç†æ€§è¡ŒåŠ¨ä¹Ÿå‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œæˆå‘˜ä»¬å¯¹ç»„ç»‡ä½¿å‘½å’Œä»·å€¼ç†å¿µçš„è®¤åŒ
    æ„æˆäº†ç»„ç»‡å‡èšåŠ›çš„åŸºç¡€ã€‚
    
    ç†æ€§åŒ–è¿‡ç¨‹åœ¨ç»„ç»‡ä¸­è¡¨ç°å¾—å°¤ä¸ºæ˜æ˜¾ã€‚é™¤é­…è¿‡ç¨‹æ·±å…¥æ¨è¿›ï¼Œ
    ä¼ ç»Ÿå’Œç¥ç§˜çš„å› ç´ è¢«ç†æ€§è®¡ç®—æ‰€å–ä»£ã€‚å½¢å¼ç†æ€§åœ¨å„ä¸ªé¢†åŸŸæ‰©å±•ï¼Œ
    ä½†å®è´¨ç†æ€§çš„ä»·å€¼å´æ—¶å¸¸è¢«å¿½è§†ï¼Œè¿™æ­£æ˜¯éŸ¦ä¼¯æ‰€å…³æ³¨çš„ç°ä»£æ€§å›°å¢ƒã€‚
    """
    
    print("1. ä¼˜åŒ–ç‰ˆç¤¾ä¼šè¡ŒåŠ¨ç±»å‹å­¦åˆ†æ")
    print("-" * 50)
    
    # æ‰§è¡Œä¼˜åŒ–ç‰ˆåˆ†æ
    action_results = analyzer.analyze_social_action_typology_optimized(test_text)
    
    print(f"âœ“ è¡ŒåŠ¨ç±»å‹: {action_results['action_type']}")
    print(f"âœ“ ç†æ€§åˆ†æ•°: {action_results['rationality_score']:.2f}")
    print(f"âœ“ è¡ŒåŠ¨ç±»å‹å­¦è´¨é‡: {action_results['quality_metrics']['overall_quality']:.2f}/10")
    
    # è¯¦ç»†è´¨é‡æŒ‡æ ‡
    quality = action_results['quality_metrics']
    print(f"  - å®Œæ•´æ€§: {quality['completeness']:.2f}")
    print(f"  - å¹³è¡¡æ€§: {quality['balance']:.2f}")
    print(f"  - æ¸…æ™°åº¦: {quality['clarity']:.2f}")
    print(f"  - å¹³å‡åˆ†: {quality['avg_score']:.2f}")
    
    print("\n2. å„ç±»å‹è¡ŒåŠ¨è¯¦ç»†åˆ†æ")
    print("-" * 50)
    
    action_types = ['purposive_rationality', 'value_rationality', 'affective_action', 'traditional_action']
    type_names = ['ç›®çš„ç†æ€§', 'ä»·å€¼ç†æ€§', 'æƒ…æ„Ÿæ€§', 'ä¼ ç»Ÿæ€§']
    
    for action_type, type_name in zip(action_types, type_names):
        if action_type in action_results:
            result = action_results[action_type]
            print(f"âœ“ {type_name}:")
            print(f"  - åˆ†æ•°: {result['score']:.2f}")
            print(f"  - ç­‰çº§: {result['level']}")
            print(f"  - è¯é¢‘åˆ†æ•°: {result['word_frequency_score']:.2f}")
            print(f"  - å…³é”®è¯åˆ†æ•°: {result['keyword_score']:.2f}")
            print(f"  - è¯­ä¹‰åˆ†æ•°: {result['semantic_score']:.2f}")
            print(f"  - æ¨¡å¼åˆ†æ•°: {result['pattern_score']:.2f}")
    
    print("\n3. æ„ä¹‰ç»“æ„åˆ†æ")
    print("-" * 50)
    
    meaning_structure = action_results['meaning_structure']
    for meaning_type, data in meaning_structure.items():
        print(f"âœ“ {meaning_type}:")
        print(f"  - é¢‘æ¬¡: {data['frequency']}")
        print(f"  - å…³é”®è¯åˆ†æ•°: {data['keyword_score']}")
        print(f"  - ç»¼åˆåˆ†æ•°: {data['composite_score']}")
        print(f"  - æ˜¾è‘—åº¦: {data['prominence']}")
    
    print("\n4. è´¨é‡æå‡æ•ˆæœåˆ†æ")
    print("-" * 50)
    
    # ä¸åŸå§‹ç‰ˆæœ¬å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰
    original_scores = {
        'action_typology': 3.83,  # åŸå§‹ç‰ˆæœ¬
        'rationalization': 3.83,
        'authority': 3.83,
        'bureaucracy': 3.83
    }
    
    optimized_scores = {
        'action_typology': action_results['quality_metrics']['overall_quality']
    }
    
    improvement = float(optimized_scores['action_typology']) - float(original_scores['action_typology'])
    
    print(f"âœ“ è¡ŒåŠ¨ç±»å‹å­¦è´¨é‡æå‡:")
    print(f"  - åŸå§‹ç‰ˆæœ¬: {original_scores['action_typology']:.2f}/10")
    print(f"  - ä¼˜åŒ–ç‰ˆæœ¬: {optimized_scores['action_typology']:.2f}/10")
    print(f"  - æå‡å¹…åº¦: {improvement:.2f} ({improvement/original_scores['action_typology']*100:.1f}%)")
    
    # è´¨é‡ç­‰çº§è¯„ä¼°
    if optimized_scores['action_typology'] >= 8.0:
        quality_grade = "ä¼˜ç§€"
    elif optimized_scores['action_typology'] >= 6.0:
        quality_grade = "è‰¯å¥½"
    elif optimized_scores['action_typology'] >= 4.0:
        quality_grade = "ä¸€èˆ¬"
    else:
        quality_grade = "éœ€è¦æ”¹è¿›"
    
    print(f"âœ“ è´¨é‡ç­‰çº§: {quality_grade}")
    
    print("\n5. ç¬¬ä¸€æ€§åŸç†æ”¹è¿›æ•ˆæœéªŒè¯")
    print("-" * 50)
    
    improvements = [
        "âœ“ å¤šç»´åº¦è¯­ä¹‰åˆ†æï¼šè¯é¢‘ã€å…³é”®è¯ã€è¯­ä¹‰ã€æ¨¡å¼å››ç»´åº¦è¯„åˆ†",
        "âœ“ åŠ¨æ€æƒé‡åˆ†é…ï¼šæ ¹æ®è¯æ±‡ç±»å‹é‡è¦æ€§è°ƒæ•´æƒé‡",
        "âœ“ è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´ï¼šé¿å…ä½åˆ†è¢«è¿‡åº¦å‹åˆ¶",
        "âœ“ ç»¼åˆè¯æ®æå–ï¼šå¤šç»´åº¦ç›¸å…³æ€§è¯„ä¼°",
        "âœ“ ä¼˜åŒ–è´¨é‡è¯„ä¼°ï¼šå®Œæ•´æ€§ã€å¹³è¡¡æ€§ã€æ¸…æ™°åº¦ã€æ·±åº¦å››ç»´åº¦",
        "âœ“ æœ€ä½è´¨é‡ä¿éšœï¼šç¡®ä¿åŸºç¡€è´¨é‡æ°´å¹³"
    ]
    
    for improvement in improvements:
        print(improvement)
    
    print("\n6. è´¨é‡æå‡æ€»ç»“")
    print("-" * 50)
    
    if improvement > 2.0:
        print("ğŸ‰ è´¨é‡æå‡æ˜¾è‘—ï¼ä¼˜åŒ–æ•ˆæœæ˜æ˜¾")
    elif improvement > 1.0:
        print("âœ… è´¨é‡æœ‰æ‰€æå‡ï¼Œä¼˜åŒ–æœ‰æ•ˆ")
    elif improvement > 0.0:
        print("ğŸ“ˆ è´¨é‡ç•¥æœ‰æå‡ï¼Œä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print("âš ï¸  è´¨é‡æå‡ä¸æ˜æ˜¾ï¼Œéœ€è¦é‡æ–°å®¡è§†ä¼˜åŒ–ç­–ç•¥")
    
    print(f"\næ ¸å¿ƒæ”¹è¿›ï¼šä» {original_scores['action_typology']:.2f}/10 æå‡åˆ° {optimized_scores['action_typology']:.2f}/10")
    print(f"æå‡å¹…åº¦ï¼š{improvement:.2f}åˆ† ({improvement/original_scores['action_typology']*100:.1f}%)")
    
    return True


def test_comprehensive_quality():
    """å…¨é¢è´¨é‡æµ‹è¯•"""
    
    print("\n=== å…¨é¢è´¨é‡æµ‹è¯• ===\n")
    
    analyzer = OptimizedWeberianAnalyzer()
    
    # å¤šä¸ªæµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'name': 'é«˜åº¦ç†æ€§åŒ–æ–‡æœ¬',
            'text': '''
            ç°ä»£ä¼ä¸šä»¥æ•ˆç‡æœ€å¤§åŒ–ä¸ºç›®æ ‡ï¼Œé€šè¿‡ç§‘å­¦ç®¡ç†å’Œç†æ€§å†³ç­–å®ç°ç»„ç»‡ç›®æ ‡ã€‚
            ç®¡ç†è€…åŸºäºæ•°æ®å’Œé€»è¾‘åˆ†æåˆ¶å®šç­–ç•¥ï¼Œå‘˜å·¥æŒ‰ç…§è§„ç« åˆ¶åº¦æ‰§è¡Œä»»åŠ¡ã€‚
            è¿™ç§ç†æ€§åŒ–çš„ç®¡ç†æ¨¡å¼ç¡®ä¿äº†ç»„ç»‡çš„é«˜æ•ˆè¿è½¬å’Œå¯æŒç»­å‘å±•ã€‚
            '''
        },
        {
            'name': 'æ··åˆå‹æ–‡æœ¬',
            'text': '''
            ä¼ ç»Ÿå®¶æ—ä¼ä¸šæ—¢ç»§æ‰¿äº†å†å²æ‚ ä¹…çš„ç»è¥ç†å¿µï¼Œåˆç§¯æé‡‡ç”¨ç°ä»£ç®¡ç†æ–¹æ³•ã€‚
            åˆ›å§‹äººçš„ä¸ªäººé­…åŠ›å’Œé¢†å¯¼æ‰èƒ½åœ¨ä¼ä¸šä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œ
            åŒæ—¶ä¹Ÿå»ºç«‹äº†å®Œå–„çš„åˆ¶åº¦ä½“ç³»æ¥è§„èŒƒä¼ä¸šè¿ä½œã€‚
            '''
        },
        {
            'name': 'ä½ç†æ€§åŒ–æ–‡æœ¬',
            'text': '''
            å°ä½œåŠä¸»è¦ä¾é å¸ˆå‚…çš„ç»éªŒå’Œç›´è§‰è¿›è¡Œç”Ÿäº§ï¼Œç¼ºä¹ç§‘å­¦çš„è§„åˆ’å’Œç®¡ç†ã€‚
            ç”Ÿäº§è¿‡ç¨‹æ›´å¤šä¾èµ–ä¼ ç»Ÿæ‰‹è‰ºå’Œä¸ªäººæŠ€èƒ½ï¼Œæƒ…æ„Ÿå› ç´ åœ¨å†³ç­–ä¸­å ä¸»å¯¼åœ°ä½ã€‚
            è¿™ç§ç»è¥æ¨¡å¼è™½ç„¶ä¿æŒäº†ä¼ ç»Ÿç‰¹è‰²ï¼Œä½†æ•ˆç‡ç›¸å¯¹è¾ƒä½ã€‚
            '''
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
        print("-" * 40)
        
        action_results = analyzer.analyze_social_action_typology_optimized(test_case['text'])
        quality_score = action_results['quality_metrics']['overall_quality']
        
        results.append({
            'case': test_case['name'],
            'quality_score': quality_score,
            'action_type': action_results['action_type']
        })
        
        print(f"è´¨é‡åˆ†æ•°: {quality_score:.2f}/10")
        print(f"è¡ŒåŠ¨ç±»å‹: {action_results['action_type']}")
        print()
    
    # ç»Ÿè®¡åˆ†æ
    avg_quality = sum(r['quality_score'] for r in results) / len(results)
    print("=== ç»Ÿè®¡åˆ†æ ===")
    print(f"å¹³å‡è´¨é‡åˆ†æ•°: {avg_quality:.2f}/10")
    print(f"æœ€é«˜è´¨é‡åˆ†æ•°: {max(r['quality_score'] for r in results):.2f}/10")
    print(f"æœ€ä½è´¨é‡åˆ†æ•°: {min(r['quality_score'] for r in results):.2f}/10")
    
    quality_distribution = {
        'ä¼˜ç§€': len([r for r in results if r['quality_score'] >= 8.0]),
        'è‰¯å¥½': len([r for r in results if 6.0 <= r['quality_score'] < 8.0]),
        'ä¸€èˆ¬': len([r for r in results if 4.0 <= r['quality_score'] < 6.0]),
        'éœ€è¦æ”¹è¿›': len([r for r in results if r['quality_score'] < 4.0])
    }
    
    print("\nè´¨é‡åˆ†å¸ƒ:")
    for grade, count in quality_distribution.items():
        print(f"- {grade}: {count} ä¸ªç”¨ä¾‹")
    
    return avg_quality >= 6.0


if __name__ == "__main__":
    print("å¼€å§‹è´¨é‡æå‡æµ‹è¯•...")
    
    success1 = test_quality_improvement()
    success2 = test_comprehensive_quality()
    
    if success1 and success2:
        print("\nğŸ‰ è´¨é‡æå‡æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        print("ä¼˜åŒ–ç‰ˆéŸ¦ä¼¯åˆ†æå™¨è´¨é‡æ˜¾è‘—æå‡ï¼Œå¯ä¿¡å¯è¡Œï¼")
    else:
        print("\nâš ï¸  è´¨é‡æå‡æµ‹è¯•éƒ¨åˆ†å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    sys.exit(0 if success1 and success2 else 1)